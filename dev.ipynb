{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI-powered virtual assistant designed to provide helpful information and assist with various tasks. I am constantly learning and expanding my knowledge base to better assist users like yourself. I can help answer questions, provide recommendations, engage in conversation, and perform certain tasks based on your requests. Is there anything specific you would like assistance with?"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Your a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about you\"},\n",
    "    ],\n",
    "    temperature=1,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "\n",
    "    if content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_search.text_retriever_class import TextRetriever, TypesenseRetriever\n",
    "\n",
    "retriever = TypesenseRetriever(\n",
    "    main_categorization_model_dir=\"./text_search/models/main_category_model\",\n",
    "    subcategorization_model_dir=\"./text_search/models/subcategory_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = retriever._combine_categorization_with_search(\"How can I apply?\", top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I apply?',\n",
       " 'categories': {'main_categories': ['graduate',\n",
       "   'support',\n",
       "   'life',\n",
       "   'academics',\n",
       "   'admissions',\n",
       "   'library',\n",
       "   'about',\n",
       "   'alumni',\n",
       "   'bsg',\n",
       "   'scholarships-aid',\n",
       "   'live',\n",
       "   'research-foundation'],\n",
       "  'sub_categories': []},\n",
       " 'response': {'results': [{'code': 400,\n",
       "    'error': 'Parameter `limit` must be an unsigned integer.'}]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n"
     ]
    }
   ],
   "source": [
    "if 'code' in search['response']['results'][0].keys():\n",
    "    print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hits'"
     ]
    }
   ],
   "source": [
    "results = [x['document']['context'] for x in search['response']['results'][0]['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It helps improve motivation and often improves performance. Too much tension, however, hinders performance and becomes damaging. If you experience extreme nervousness, dread or fear before exams and have put forth your best effort to prepare in advance, you may be suffering from test anxiety. Simply put, test anxiety prevents you from doing your best on exams. Symptoms of test anxiety can be separated into 2 categories: mental stress & physical stress.',\n",
       " 'people sitting nearby, watching the clock, awareness of when others finish their test, classroom noise, etc.). Mental blocks or a general inability to perform complex intellectual task. Test anxiety is more intense than average nervousness before a test and is not subject specific (i.e. only occurs during math tests). Not caused by lack of preparation or poor test testing skills (although, these circumstances will likely cause someone with test anxiety more nervousness).']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container 'typesense_container' is not running. Starting it now...\n",
      "Continuing with other tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240112 00:52:31.554486     1 typesense_server_utils.cpp:334] Starting Typesense 0.25.2\n",
      "I20240112 00:52:31.554533     1 typesense_server_utils.cpp:337] Typesense is using jemalloc.\n",
      "I20240112 00:52:31.554898     1 typesense_server_utils.cpp:387] Thread pool size: 192\n",
      "I20240112 00:52:31.573473     1 store.h:64] Initializing DB by opening state dir: /data/db\n",
      "I20240112 00:52:31.589643     1 store.h:64] Initializing DB by opening state dir: /data/meta\n",
      "I20240112 00:52:31.597987     1 ratelimit_manager.cpp:546] Loaded 0 rate limit rules.\n",
      "I20240112 00:52:31.598008     1 ratelimit_manager.cpp:547] Loaded 0 rate limit bans.\n",
      "I20240112 00:52:31.598037     1 typesense_server_utils.cpp:507] Starting API service...\n",
      "I20240112 00:52:31.598134     1 http_server.cpp:178] Typesense has started listening on port 8108\n",
      "I20240112 00:52:31.598254   647 batched_indexer.cpp:124] Starting batch indexer with 192 threads.\n",
      "I20240112 00:52:31.598440   646 typesense_server_utils.cpp:235] Since no --nodes argument is provided, starting a single node Typesense cluster.\n",
      "I20240112 00:52:31.615578   646 server.cpp:1107] Server[braft::RaftStatImpl+braft::FileServiceImpl+braft::RaftServiceImpl+braft::CliServiceImpl] is serving on port=8107.\n",
      "I20240112 00:52:31.615607   646 server.cpp:1110] Check out http://216d700a69d1:8107 in web browser.\n",
      "I20240112 00:52:31.615754   646 raft_server.cpp:68] Nodes configuration: 172.17.0.2:8107:8108\n",
      "I20240112 00:52:31.616080   646 log.cpp:690] Use murmurhash32 as the checksum type of appending entries\n",
      "I20240112 00:52:31.616114   646 log.cpp:1172] log load_meta /data/state/log/log_meta first_log_index: 371 time: 19\n",
      "I20240112 00:52:31.616132   646 log.cpp:1112] load open segment, path: /data/state/log first_index: 349\n",
      "I20240112 00:52:31.616492   699 raft_server.cpp:522] on_snapshot_load\n",
      "I20240112 00:52:31.617022   699 store.h:299] rm /data/db success\n",
      "I20240112 00:52:31.617246   699 store.h:309] copy snapshot /data/state/snapshot/snapshot_00000000000000000371/db_snapshot to /data/db success\n",
      "I20240112 00:52:31.617261   699 store.h:64] Initializing DB by opening state dir: /data/db\n",
      "I20240112 00:52:31.623693   647 batched_indexer.cpp:129] BatchedIndexer skip_index: -9999\n",
      "I20240112 00:52:31.630971   699 store.h:323] DB open success!\n",
      "I20240112 00:52:31.630990   699 raft_server.cpp:501] Loading collections from disk...\n",
      "I20240112 00:52:31.630993   699 collection_manager.cpp:187] CollectionManager::load()\n",
      "I20240112 00:52:31.632009   699 auth_manager.cpp:34] Indexing 0 API key(s) found on disk.\n",
      "I20240112 00:52:31.632037   699 collection_manager.cpp:207] Loading upto 96 collections in parallel, 1000 documents at a time.\n",
      "I20240112 00:52:31.632048   699 collection_manager.cpp:216] Found 1 collection(s) on disk.\n",
      "I20240112 00:52:31.634469   883 text_embedder_manager.cpp:14] Validating and initializing remote model: openai/text-embedding-ada-002\n",
      "E20240112 00:52:31.634495   883 raft_server.cpp:967] Could not get leader url as node is not initialized!\n",
      "E20240112 00:52:31.878573   883 raft_server.cpp:967] Could not get leader url as node is not initialized!\n",
      "I20240112 00:52:32.135681   883 text_embedder.cpp:61] Initializing remote embedding model: openai/text-embedding-ada-002\n",
      "I20240112 00:52:32.135711   883 collection_manager.cpp:91] Model init done.\n",
      "I20240112 00:52:32.135723   883 collection_manager.cpp:137] Found collection brockport_data_v1 with 4 memory shards.\n",
      "I20240112 00:52:32.136672   883 collection_manager.cpp:1359] Loading collection brockport_data_v1\n",
      "I20240112 00:52:42.013960   883 collection_manager.cpp:1477] Indexed 17222/17222 documents into collection brockport_data_v1\n",
      "I20240112 00:52:42.014024   883 collection_manager.cpp:255] Loaded 1 collection(s) so far\n",
      "I20240112 00:52:42.016744   699 collection_manager.cpp:316] Loaded 1 collection(s).\n",
      "I20240112 00:52:42.017956   699 collection_manager.cpp:320] Initializing batched indexer from snapshot state...\n",
      "I20240112 00:52:42.017992   699 batched_indexer.cpp:471] Restored 0 in-flight requests from snapshot.\n",
      "I20240112 00:52:42.017999   699 raft_server.cpp:508] Finished loading collections from disk.\n",
      "I20240112 00:52:42.018024   699 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.018074   699 snapshot_executor.cpp:264] node default_group:172.17.0.2:8107:8108 snapshot_load_done, last_included_index: 371 last_included_term: 11 peers: \"172.17.0.2:8107:8108\"\n",
      "I20240112 00:52:42.018221   646 raft_meta.cpp:521] Loaded single stable meta, path /data/state/meta term 16 votedfor 172.17.0.2:8107:8108 time: 23\n",
      "I20240112 00:52:42.018251   646 node.cpp:608] node default_group:172.17.0.2:8107:8108 init, term: 16 last_log_id: (index=377,term=16) conf: 172.17.0.2:8107:8108 old_conf: \n",
      "I20240112 00:52:42.018270   646 node.cpp:1645] node default_group:172.17.0.2:8107:8108 term 16 start vote and grant vote self\n",
      "I20240112 00:52:42.026882   646 raft_meta.cpp:546] Saved single stable meta, path /data/state/meta term 17 votedfor 172.17.0.2:8107:8108 time: 8535\n",
      "I20240112 00:52:42.026909   646 node.cpp:1899] node default_group:172.17.0.2:8107:8108 term 17 become leader of group 172.17.0.2:8107:8108 \n",
      "I20240112 00:52:42.026942   646 raft_server.cpp:134] Node last_index: 377\n",
      "I20240112 00:52:42.026954   646 typesense_server_utils.cpp:283] Typesense peering service is running on 172.17.0.2:8107\n",
      "I20240112 00:52:42.026957   646 typesense_server_utils.cpp:284] Snapshot interval configured as: 3600s\n",
      "I20240112 00:52:42.026960   646 typesense_server_utils.cpp:285] Snapshot max byte count configured as: 4194304\n",
      "W20240112 00:52:42.026963   646 controller.cpp:1487] SIGINT was installed with 1\n",
      "I20240112 00:52:42.026970   646 raft_server.cpp:557] Term: 17, pending_queue: 1, last_index: 377, committed: 0, known_applied: 371, applying: 0, pending_writes: 0, queued_writes: 0, local_sequence: 467525\n",
      "W20240112 00:52:42.026983   646 node.cpp:843] [default_group:172.17.0.2:8107:8108 ] Refusing concurrent configuration changing\n",
      "E20240112 00:52:42.027020   691 raft_server.h:62] Peer refresh failed, error: Doing another configuration change\n",
      "I20240112 00:52:42.028046   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028075   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028085   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028092   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028108   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028118   704 raft_server.h:285] Configuration of this group is 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028129   704 node.cpp:3298] node default_group:172.17.0.2:8107:8108 reset ConfigurationCtx, new_peers: 172.17.0.2:8107:8108, old_peers: 172.17.0.2:8107:8108\n",
      "I20240112 00:52:42.028136   704 raft_server.h:268] Node becomes leader, term: 17\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "import subprocess\n",
    "\n",
    "def is_container_running(container_name):\n",
    "    client = docker.from_env()\n",
    "    try:\n",
    "        container = client.containers.get(container_name)\n",
    "        return container.status == 'running'\n",
    "    except docker.errors.NotFound:\n",
    "        return False\n",
    "\n",
    "def start_typesense_container():\n",
    "    command = (\n",
    "        \"docker run --name typesense_container -p 8108:8108 \"\n",
    "        \"-v /home/msaad/typesense-data:/data \"\n",
    "        \"typesense/typesense:0.25.2 \"\n",
    "        \"--data-dir /data \"\n",
    "        \"--api-key=xyz \"\n",
    "        \"--enable-cors\"\n",
    "    )\n",
    "    subprocess.Popen(command, shell=True)\n",
    "\n",
    "container_name = \"typesense_container\"\n",
    "\n",
    "if not is_container_running(container_name):\n",
    "    print(f\"Container '{container_name}' is not running. Starting it now...\")\n",
    "    start_typesense_container()\n",
    "else:\n",
    "    print(f\"Container '{container_name}' is already running.\")\n",
    "\n",
    "# Your script will continue from here\n",
    "print(\"Continuing with other tasks...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container 'typesense_container' has been stopped.\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "container_name = \"typesense_container\"\n",
    "client = docker.from_env()\n",
    "try:\n",
    "    container = client.containers.get(container_name)\n",
    "    container.stop()\n",
    "    container.remove()\n",
    "    print(f\"Container '{container_name}' has been stopped.\")\n",
    "except docker.errors.NotFound:\n",
    "    print(f\"Container '{container_name}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
