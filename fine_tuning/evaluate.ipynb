{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:04:10.020813: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-07 12:04:10.046808: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 12:04:10.831090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from finetune_class import FineTunedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a745fa237a94f36955b8665c559265d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FineTunedModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, indeed! SUNY Brockport offers an exciting Bachelor of Science in Engineering program with several concentrations such as Computer Engineering, Electrical Engineering, Mechanical Engineering, and Materials Science & Engineering. It's a fantastic way to gain a solid foundation in science and mathematics while exploring the fascinating world of engineering.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"Is there an engineering major at SUNY Brockport?\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Is there a math major at SUNY Brockport?\",\n",
    "    \"Is there an engineering major at SUNY Brockport?\",\n",
    "    \"Tell me about the nursing major.\",\n",
    "    \"How can I get involved in undergraduate research?\",\n",
    "    \"How can I get involved in clubs?\",\n",
    "    \"What options are there for financial aid at Brockport?\",\n",
    "    \"How can I report sexual misconduct?\",\n",
    "    \"Can I get credit for completing an internship in the math department?\",\n",
    "    \"Is there a gym available to students on campus?\",\n",
    "    \"How can I apply to SUNY Brockport?\",\n",
    "    \"What is the meaning of life?\",\n",
    "]\n",
    "\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for q in questions:\n",
    "        f.write(f\"Question: {q}\\n\")\n",
    "        f.write(f\"Answer: {model(q, temperature=0.01)}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Question\": questions,\n",
    "        \"Answer\": [model(q, temperature=0.01) for q in questions],\n",
    "    }\n",
    ")\n",
    "\n",
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Is there a math major at SUNY Brockport?\n",
       "1      Is there an engineering major at SUNY Brockport?\n",
       "2                      Tell me about the nursing major.\n",
       "3     How can I get involved in undergraduate research?\n",
       "4                      How can I get involved in clubs?\n",
       "5     What options are there for financial aid at Br...\n",
       "6                   How can I report sexual misconduct?\n",
       "7     Can I get credit for completing an internship ...\n",
       "8       Is there a gym available to students on campus?\n",
       "9                    How can I apply to SUNY Brockport?\n",
       "10                         What is the meaning of life?\n",
       "Name: Question, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Question'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 11:42:27.455868: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-07 11:42:27.639693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 11:42:28.449103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576148b53f4143ce9b8a7eeb6a93187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    TextIteratorStreamer, \n",
    "    BitsAndBytesConfig, \n",
    "    pipeline,\n",
    "    GenerationConfig\n",
    ")\n",
    "from typing import Optional\n",
    "from threading import Thread\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"msaad02/BrockportGPT-7b\", device_map={\"\": 0})\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"msaad02/BrockportGPT-7b\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type='nf4'\n",
    "    ),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = lambda question: f\"\"\"\\\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for SUNY Brockport, a public college in Brockport, New York. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{question} [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = prompt(\"Is there a math major at SUNY Brockport?\")\n",
    "\n",
    "inputs = tokenizer(question, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.decode(i) for i in range(32000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    **inputs, \n",
    "    generation_config=GenerationConfig(\n",
    "        output_scores=True,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=15,\n",
    "        temperature=0.01\n",
    "    ),\n",
    "    return_dict_in_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 100.0,\n",
       " 'Ab': 0.0,\n",
       " '<unk>': 0.0,\n",
       " '<s>': 0.0,\n",
       " '</s>': 0.0,\n",
       " '\\x00': 0.0,\n",
       " '\\x01': 0.0,\n",
       " '\\x02': 0.0,\n",
       " '\\x03': 0.0,\n",
       " '\\x04': 0.0}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature = 0.01\n",
    "probs = torch.nn.functional.softmax(output['scores'][0][0], dim=0)\n",
    "argsort = probs.argsort(descending=True)\n",
    "d = {token: round(prob*100,3) for token, prob in zip([tokens[idx] for idx in argsort[0:10]], probs[argsort][0:10].cpu().numpy())}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 29.019,\n",
       " 'Ab': 22.6,\n",
       " 'No': 7.81,\n",
       " 'Current': 5.368,\n",
       " 'Wh': 4.737,\n",
       " 'S': 4.45,\n",
       " 'At': 3.466,\n",
       " 'We': 2.699,\n",
       " 'There': 2.536,\n",
       " 'Un': 2.382}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature = 1.0\n",
    "probs = torch.nn.functional.softmax(output['scores'][0][0], dim=0)\n",
    "argsort = probs.argsort(descending=True)\n",
    "d = {token: round(prob*100,3) for token, prob in zip([tokens[idx] for idx in argsort[0:10]], probs[argsort][0:10].cpu().numpy())}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(output['scores'][1][0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5890"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.cpu().numpy().round(2).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.cpu().numpy().round(2)[5890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs['lying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "probsprobs = torch.nn.functional.softmax(output['scores'][1][0], dim=0)\n",
    "a = probsprobs[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5890, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probsprobs.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0.0,\n",
       " '<s>': 0.0,\n",
       " '</s>': 0.0,\n",
       " '\\x00': 0.0,\n",
       " '\\x01': 0.0,\n",
       " '\\x02': 0.0,\n",
       " '\\x03': 0.0,\n",
       " '\\x04': 0.0,\n",
       " '\\x05': 0.0,\n",
       " '\\x06': 0.0,\n",
       " '\\x07': 0.0,\n",
       " '\\x08': 0.0,\n",
       " '\\t': 0.0,\n",
       " '\\n': 0.0,\n",
       " '\\x0b': 0.0,\n",
       " '\\x0c': 0.0,\n",
       " '\\r': 0.0,\n",
       " '\\x0e': 0.0,\n",
       " '\\x0f': 0.0,\n",
       " '\\x10': 0.0,\n",
       " '\\x11': 0.0,\n",
       " '\\x12': 0.0,\n",
       " '\\x13': 0.0,\n",
       " '\\x14': 0.0,\n",
       " '\\x15': 0.0,\n",
       " '\\x16': 0.0,\n",
       " '\\x17': 0.0,\n",
       " '\\x18': 0.0,\n",
       " '\\x19': 0.0,\n",
       " '\\x1a': 0.0,\n",
       " '\\x1b': 0.0,\n",
       " '\\x1c': 0.0,\n",
       " '\\x1d': 0.0,\n",
       " '\\x1e': 0.0,\n",
       " '\\x1f': 0.0,\n",
       " '': 0.0,\n",
       " '!': 0.0,\n",
       " '\"': 0.0,\n",
       " '#': 0.0,\n",
       " '$': 0.0,\n",
       " '%': 0.0,\n",
       " '&': 0.0,\n",
       " \"'\": 0.0,\n",
       " '(': 0.0,\n",
       " ')': 0.0,\n",
       " '*': 0.0,\n",
       " '+': 0.0,\n",
       " ',': 0.0,\n",
       " '-': 0.0,\n",
       " '.': 0.0,\n",
       " '/': 0.0,\n",
       " '0': 0.0,\n",
       " '1': 0.0,\n",
       " '2': 0.0,\n",
       " '3': 0.0,\n",
       " '4': 0.0,\n",
       " '5': 0.0,\n",
       " '6': 0.0,\n",
       " '7': 0.0,\n",
       " '8': 0.0,\n",
       " '9': 0.0,\n",
       " ':': 0.0,\n",
       " ';': 0.0,\n",
       " '<': 0.0,\n",
       " '=': 0.0,\n",
       " '>': 0.0,\n",
       " '?': 0.0,\n",
       " '@': 0.0,\n",
       " 'A': 0.0,\n",
       " 'B': 0.0,\n",
       " 'C': 0.0,\n",
       " 'D': 0.0,\n",
       " 'E': 0.0,\n",
       " 'F': 0.0,\n",
       " 'G': 0.0,\n",
       " 'H': 0.0,\n",
       " 'I': 0.0,\n",
       " 'J': 0.0,\n",
       " 'K': 0.0,\n",
       " 'L': 0.0,\n",
       " 'M': 0.0,\n",
       " 'N': 0.0,\n",
       " 'O': 0.0,\n",
       " 'P': 0.0,\n",
       " 'Q': 0.0,\n",
       " 'R': 0.0,\n",
       " 'S': 0.0,\n",
       " 'T': 0.0,\n",
       " 'U': 0.0,\n",
       " 'V': 0.0,\n",
       " 'W': 0.0,\n",
       " 'X': 0.0,\n",
       " 'Y': 0.0,\n",
       " 'Z': 0.0,\n",
       " '[': 0.0,\n",
       " '\\\\': 0.0,\n",
       " ']': 0.0,\n",
       " '^': 0.0,\n",
       " '_': 0.0,\n",
       " '`': 0.0,\n",
       " 'a': 0.0,\n",
       " 'b': 0.0,\n",
       " 'c': 0.0,\n",
       " 'd': 0.0,\n",
       " 'e': 0.0,\n",
       " 'f': 0.0,\n",
       " 'g': 0.0,\n",
       " 'h': 0.0,\n",
       " 'i': 0.0,\n",
       " 'j': 0.0,\n",
       " 'k': 0.0,\n",
       " 'l': 0.0,\n",
       " 'm': 0.0,\n",
       " 'n': 0.0,\n",
       " 'o': 0.0,\n",
       " 'p': 0.0,\n",
       " 'q': 0.0,\n",
       " 'r': 0.0,\n",
       " 's': 0.0,\n",
       " 't': 0.0,\n",
       " 'u': 0.0,\n",
       " 'v': 0.0,\n",
       " 'w': 0.0,\n",
       " 'x': 0.0,\n",
       " 'y': 0.0,\n",
       " 'z': 0.0,\n",
       " '{': 0.0,\n",
       " '|': 0.0,\n",
       " '}': 0.0,\n",
       " '~': 0.0,\n",
       " '\\x7f': 0.0,\n",
       " '�': 0.0,\n",
       " ' ': 0.0,\n",
       " 'er': 0.0,\n",
       " 'in': 0.0,\n",
       " 'en': 0.0,\n",
       " 'on': 0.0,\n",
       " 'th': 0.0,\n",
       " 'es': 0.0,\n",
       " '   ': 0.0,\n",
       " 'at': 0.0,\n",
       " 'or': 0.0,\n",
       " 'an': 0.0,\n",
       " 'is': 0.0,\n",
       " 're': 0.0,\n",
       " 'it': 0.0,\n",
       " 'the': 0.0,\n",
       " 'ar': 0.0,\n",
       " 'le': 0.0,\n",
       " 'ou': 0.0,\n",
       " 'al': 0.0,\n",
       " 'ed': 0.0,\n",
       " 'om': 0.0,\n",
       " 'ion': 0.0,\n",
       " 'ing': 0.0,\n",
       " 'ic': 0.0,\n",
       " 'as': 0.0,\n",
       " 'el': 0.0,\n",
       " 'ent': 0.0,\n",
       " 'nd': 0.0,\n",
       " 'et': 0.0,\n",
       " 'st': 0.0,\n",
       " 'to': 0.0,\n",
       " 'ch': 0.0,\n",
       " 'ro': 0.0,\n",
       " '       ': 0.0,\n",
       " 'il': 0.0,\n",
       " 'of': 0.0,\n",
       " 'de': 0.0,\n",
       " 'ct': 0.0,\n",
       " 'am': 0.0,\n",
       " 'and': 0.0,\n",
       " 'ol': 0.0,\n",
       " 'im': 0.0,\n",
       " 'ot': 0.0,\n",
       " 'ad': 0.0,\n",
       " 'ut': 0.0,\n",
       " 'em': 0.0,\n",
       " 'ur': 0.0,\n",
       " 'id': 0.0,\n",
       " 'ig': 0.0,\n",
       " 'ra': 0.0,\n",
       " 'qu': 0.0,\n",
       " 'ow': 0.0,\n",
       " 'est': 0.0,\n",
       " 'se': 0.0,\n",
       " 've': 0.0,\n",
       " 'ce': 0.0,\n",
       " 'ie': 0.0,\n",
       " 'un': 0.0,\n",
       " 'ag': 0.0,\n",
       " 'ul': 0.0,\n",
       " 'he': 0.0,\n",
       " 'end': 0.0,\n",
       " 'ode': 0.0,\n",
       " 'ter': 0.0,\n",
       " 'ment': 0.0,\n",
       " 'os': 0.0,\n",
       " 'if': 0.0,\n",
       " 'ation': 0.0,\n",
       " 'for': 0.0,\n",
       " 'you': 0.0,\n",
       " 'be': 0.0,\n",
       " 'ly': 0.0,\n",
       " 'ver': 0.0,\n",
       " 'ab': 0.0,\n",
       " 'te': 0.0,\n",
       " 'ri': 0.0,\n",
       " 'us': 0.0,\n",
       " 'wh': 0.0,\n",
       " 'con': 0.0,\n",
       " 'ir': 0.0,\n",
       " 'ck': 0.0,\n",
       " 'eg': 0.0,\n",
       " 'ay': 0.0,\n",
       " 'ith': 0.0,\n",
       " 'ist': 0.0,\n",
       " 'that': 0.0,\n",
       " 'od': 0.0,\n",
       " 'um': 0.0,\n",
       " 'ht': 0.0,\n",
       " 'code': 0.0,\n",
       " 'ate': 0.0,\n",
       " 'ess': 0.0,\n",
       " 'ere': 0.0,\n",
       " 'pp': 0.0,\n",
       " 'pro': 0.0,\n",
       " 'with': 0.0,\n",
       " 'pe': 0.0,\n",
       " 'ers': 0.0,\n",
       " 'pt': 0.0,\n",
       " ');': 0.0,\n",
       " 'lo': 0.0,\n",
       " '    ': 0.0,\n",
       " 'com': 0.0,\n",
       " 'ame': 0.0,\n",
       " 'Com': 0.0,\n",
       " 'ia': 0.0,\n",
       " 'ant': 0.0,\n",
       " 'la': 0.0,\n",
       " 'ction': 0.0,\n",
       " 'ex': 0.0,\n",
       " 'ld': 0.0,\n",
       " 'ub': 0.0,\n",
       " 'ue': 0.0,\n",
       " 'ich': 0.0,\n",
       " 'do': 0.0,\n",
       " 'iv': 0.0,\n",
       " 'ort': 0.0,\n",
       " 'art': 0.0,\n",
       " '##': 0.0,\n",
       " 'this': 0.0,\n",
       " 'ke': 0.0,\n",
       " 'ha': 0.0,\n",
       " 'out': 0.0,\n",
       " 'The': 0.0,\n",
       " 'not': 0.0,\n",
       " 'ne': 0.0,\n",
       " 'ill': 0.0,\n",
       " 'ci': 0.0,\n",
       " 'rom': 0.0,\n",
       " 'ine': 0.0,\n",
       " '//': 0.0,\n",
       " 'op': 0.0,\n",
       " 'egin': 0.0,\n",
       " 'Comment': 0.0,\n",
       " '               ': 0.0,\n",
       " 'begin': 0.0,\n",
       " 'ст': 0.0,\n",
       " 'ass': 0.0,\n",
       " 'iz': 0.0,\n",
       " ').': 0.0,\n",
       " 'og': 0.0,\n",
       " 'п': 0.0,\n",
       " 'was': 0.0,\n",
       " 'our': 0.0,\n",
       " 'ain': 0.0,\n",
       " 'на': 0.0,\n",
       " 'ge': 0.0,\n",
       " 'su': 0.0,\n",
       " 'ap': 0.0,\n",
       " 'age': 0.0,\n",
       " 'ould': 0.0,\n",
       " 'av': 0.0,\n",
       " 'xt': 0.0,\n",
       " 'ore': 0.0,\n",
       " 'ile': 0.0,\n",
       " '--': 0.0,\n",
       " 'в': 0.0,\n",
       " 'by': 0.0,\n",
       " 'li': 0.0,\n",
       " 'ath': 0.0,\n",
       " 'ра': 0.0,\n",
       " 'ber': 0.0,\n",
       " 'ach': 0.0,\n",
       " 'all': 0.0,\n",
       " 'Th': 0.0,\n",
       " 'ult': 0.0,\n",
       " 'ust': 0.0,\n",
       " 'have': 0.0,\n",
       " 'lic': 0.0,\n",
       " 'ни': 0.0,\n",
       " 'can': 0.0,\n",
       " 'tr': 0.0,\n",
       " '),': 0.0,\n",
       " 'In': 0.0,\n",
       " 'ind': 0.0,\n",
       " 'ell': 0.0,\n",
       " 'from': 0.0,\n",
       " 'ов': 0.0,\n",
       " 'able': 0.0,\n",
       " 'ost': 0.0,\n",
       " 'ect': 0.0,\n",
       " 'ight': 0.0,\n",
       " 'int': 0.0,\n",
       " 'are': 0.0,\n",
       " 'sh': 0.0,\n",
       " 'An': 0.0,\n",
       " 'с': 0.0,\n",
       " 'ata': 0.0,\n",
       " 'ire': 0.0,\n",
       " 'ord': 0.0,\n",
       " 'ity': 0.0,\n",
       " 'ard': 0.0,\n",
       " '     ': 0.0,\n",
       " 'but': 0.0,\n",
       " 'oc': 0.0,\n",
       " '=\"': 0.0,\n",
       " 'pr': 0.0,\n",
       " 'ure': 0.0,\n",
       " 'per': 0.0,\n",
       " 'ack': 0.0,\n",
       " 'ork': 0.0,\n",
       " 'ong': 0.0,\n",
       " 'ans': 0.0,\n",
       " 'ко': 0.0,\n",
       " 'ple': 0.0,\n",
       " 'des': 0.0,\n",
       " 'ok': 0.0,\n",
       " 'orm': 0.0,\n",
       " 'wer': 0.0,\n",
       " 'ak': 0.0,\n",
       " 'ase': 0.0,\n",
       " 'ph': 0.0,\n",
       " 'ac': 0.0,\n",
       " 'und': 0.0,\n",
       " 'ud': 0.0,\n",
       " 'ps': 0.0,\n",
       " 'ite': 0.0,\n",
       " 'ble': 0.0,\n",
       " 'но': 0.0,\n",
       " 'fer': 0.0,\n",
       " 'pl': 0.0,\n",
       " 'ive': 0.0,\n",
       " 'ang': 0.0,\n",
       " 'ens': 0.0,\n",
       " 'ро': 0.0,\n",
       " 'so': 0.0,\n",
       " 'ast': 0.0,\n",
       " '()': 0.0,\n",
       " 'swer': 0.0,\n",
       " 'ru': 0.0,\n",
       " 'ies': 0.0,\n",
       " 'au': 0.0,\n",
       " 'ov': 0.0,\n",
       " 'ре': 0.0,\n",
       " 'го': 0.0,\n",
       " 'der': 0.0,\n",
       " 'my': 0.0,\n",
       " 'we': 0.0,\n",
       " 'me': 0.0,\n",
       " 'nt': 0.0,\n",
       " 'urn': 0.0,\n",
       " 'your': 0.0,\n",
       " '://': 0.0,\n",
       " 'ff': 0.0,\n",
       " 'io': 0.0,\n",
       " 'estion': 0.0,\n",
       " 'ime': 0.0,\n",
       " 'lass': 0.0,\n",
       " 'и': 0.0,\n",
       " 'which': 0.0,\n",
       " 'ome': 0.0,\n",
       " 'ont': 0.0,\n",
       " 'par': 0.0,\n",
       " 'ma': 0.0,\n",
       " '\",': 0.0,\n",
       " 'о': 0.0,\n",
       " 'ft': 0.0,\n",
       " 'ial': 0.0,\n",
       " 'cc': 0.0,\n",
       " 'ound': 0.0,\n",
       " 'res': 0.0,\n",
       " 'eth': 0.0,\n",
       " 'ject': 0.0,\n",
       " 'app': 0.0,\n",
       " 'St': 0.0,\n",
       " 'ice': 0.0,\n",
       " 'act': 0.0,\n",
       " 'del': 0.0,\n",
       " 'gr': 0.0,\n",
       " 'ated': 0.0,\n",
       " 'ier': 0.0,\n",
       " '           ': 0.0,\n",
       " 'ally': 0.0,\n",
       " '..': 0.0,\n",
       " 'port': 0.0,\n",
       " 'ik': 0.0,\n",
       " 'cont': 0.0,\n",
       " 'ри': 0.0,\n",
       " 'ка': 0.0,\n",
       " 'ser': 0.0,\n",
       " 'ли': 0.0,\n",
       " 'll': 0.0,\n",
       " 'iew': 0.0,\n",
       " 'ign': 0.0,\n",
       " '_{': 0.0,\n",
       " 'put': 0.0,\n",
       " 'one': 0.0,\n",
       " 'unction': 0.0,\n",
       " 'di': 0.0,\n",
       " 'ary': 0.0,\n",
       " 'ition': 0.0,\n",
       " 'ен': 0.0,\n",
       " 'get': 0.0,\n",
       " 'val': 0.0,\n",
       " 'ran': 0.0,\n",
       " 'д': 0.0,\n",
       " 'ence': 0.0,\n",
       " 'work': 0.0,\n",
       " 'ip': 0.0,\n",
       " 'item': 0.0,\n",
       " 'ype': 0.0,\n",
       " 'his': 0.0,\n",
       " 'use': 0.0,\n",
       " 'Answer': 0.0,\n",
       " 'will': 0.0,\n",
       " 'ize': 0.0,\n",
       " 'та': 0.0,\n",
       " 'low': 0.0,\n",
       " 'Ch': 0.0,\n",
       " 'ide': 0.0,\n",
       " 'ous': 0.0,\n",
       " 'ink': 0.0,\n",
       " 'ption': 0.0,\n",
       " 'ла': 0.0,\n",
       " 'turn': 0.0,\n",
       " 'ung': 0.0,\n",
       " 'ec': 0.0,\n",
       " 'ug': 0.0,\n",
       " 'form': 0.0,\n",
       " 'htt': 0.0,\n",
       " 'oug': 0.0,\n",
       " 'ль': 0.0,\n",
       " 'no': 0.0,\n",
       " 'cl': 0.0,\n",
       " 'tt': 0.0,\n",
       " 'cri': 0.0,\n",
       " 'du': 0.0,\n",
       " 'up': 0.0,\n",
       " 'то': 0.0,\n",
       " '(\"': 0.0,\n",
       " 'ob': 0.0,\n",
       " 'ory': 0.0,\n",
       " 'ery': 0.0,\n",
       " 'iel': 0.0,\n",
       " 'str': 0.0,\n",
       " 'que': 0.0,\n",
       " 'ian': 0.0,\n",
       " 'new': 0.0,\n",
       " 'ки': 0.0,\n",
       " 'ry': 0.0,\n",
       " 'oth': 0.0,\n",
       " 'ther': 0.0,\n",
       " 'var': 0.0,\n",
       " 'would': 0.0,\n",
       " 'tern': 0.0,\n",
       " 'text': 0.0,\n",
       " 'there': 0.0,\n",
       " 'ish': 0.0,\n",
       " 'ror': 0.0,\n",
       " 'те': 0.0,\n",
       " 'set': 0.0,\n",
       " 'по': 0.0,\n",
       " 'return': 0.0,\n",
       " 'ail': 0.0,\n",
       " 'any': 0.0,\n",
       " 'It': 0.0,\n",
       " 'function': 0.0,\n",
       " '{\\\\': 0.0,\n",
       " \"',\": 0.0,\n",
       " 'és': 0.0,\n",
       " 'ale': 0.0,\n",
       " 'ан': 0.0,\n",
       " 'when': 0.0,\n",
       " 'ib': 0.0,\n",
       " 'go': 0.0,\n",
       " 'ance': 0.0,\n",
       " 'had': 0.0,\n",
       " 'Qu': 0.0,\n",
       " 'comp': 0.0,\n",
       " 'ле': 0.0,\n",
       " 'з': 0.0,\n",
       " 'math': 0.0,\n",
       " 'has': 0.0,\n",
       " 'м': 0.0,\n",
       " 'pre': 0.0,\n",
       " 'ener': 0.0,\n",
       " 'part': 0.0,\n",
       " 'elf': 0.0,\n",
       " 'die': 0.0,\n",
       " 'like': 0.0,\n",
       " 'ray': 0.0,\n",
       " 'irst': 0.0,\n",
       " 'dis': 0.0,\n",
       " 'man': 0.0,\n",
       " 'rit': 0.0,\n",
       " 'then': 0.0,\n",
       " 'class': 0.0,\n",
       " 'po': 0.0,\n",
       " 'using': 0.0,\n",
       " 'eb': 0.0,\n",
       " 'own': 0.0,\n",
       " 'some': 0.0,\n",
       " 'ces': 0.0,\n",
       " '$\\\\': 0.0,\n",
       " 'ер': 0.0,\n",
       " 'lect': 0.0,\n",
       " 'isch': 0.0,\n",
       " 'col': 0.0,\n",
       " '–': 0.0,\n",
       " 'ons': 0.0,\n",
       " 'add': 0.0,\n",
       " 'ild': 0.0,\n",
       " 'iss': 0.0,\n",
       " 'ount': 0.0,\n",
       " 'les': 0.0,\n",
       " 'vent': 0.0,\n",
       " '            ': 0.0,\n",
       " 'row': 0.0,\n",
       " 'ear': 0.0,\n",
       " 'ations': 0.0,\n",
       " 'ah': 0.0,\n",
       " 'ublic': 0.0,\n",
       " 'ank': 0.0,\n",
       " 'sp': 0.0,\n",
       " 'Wh': 0.0,\n",
       " '----': 0.0,\n",
       " 'sk': 0.0,\n",
       " 'ew': 0.0,\n",
       " 'ags': 0.0,\n",
       " 'ти': 0.0,\n",
       " 'ann': 0.0,\n",
       " '—': 0.0,\n",
       " 'ert': 0.0,\n",
       " 'ace': 0.0,\n",
       " 'sch': 0.0,\n",
       " 'need': 0.0,\n",
       " 'à': 0.0,\n",
       " 'ien': 0.0,\n",
       " 'ough': 0.0,\n",
       " 'не': 0.0,\n",
       " 'def': 0.0,\n",
       " 'ij': 0.0,\n",
       " 'ern': 0.0,\n",
       " 'what': 0.0,\n",
       " 'Ar': 0.0,\n",
       " 'wo': 0.0,\n",
       " 'ml': 0.0,\n",
       " '</': 0.0,\n",
       " 'Re': 0.0,\n",
       " 'inst': 0.0,\n",
       " 'bo': 0.0,\n",
       " 'az': 0.0,\n",
       " '###': 0.0,\n",
       " 'б': 0.0,\n",
       " 'erm': 0.0,\n",
       " 'Al': 0.0,\n",
       " 'led': 0.0,\n",
       " 'да': 0.0,\n",
       " 'ten': 0.0,\n",
       " 'ло': 0.0,\n",
       " 'comm': 0.0,\n",
       " 'ва': 0.0,\n",
       " 'data': 0.0,\n",
       " '](': 0.0,\n",
       " 'ose': 0.0,\n",
       " 'Un': 0.0,\n",
       " 'ven': 0.0,\n",
       " '...': 0.0,\n",
       " 'С': 0.0,\n",
       " 'yst': 0.0,\n",
       " '«': 0.0,\n",
       " 'ick': 0.0,\n",
       " 'ix': 0.0,\n",
       " 'у': 0.0,\n",
       " 'want': 0.0,\n",
       " 'ng': 0.0,\n",
       " 'ote': 0.0,\n",
       " 'only': 0.0,\n",
       " 'sa': 0.0,\n",
       " 'ely': 0.0,\n",
       " 'vers': 0.0,\n",
       " '))': 0.0,\n",
       " \"('\": 0.0,\n",
       " 'mod': 0.0,\n",
       " 'ava': 0.0,\n",
       " 'ton': 0.0,\n",
       " 'should': 0.0,\n",
       " 'ement': 0.0,\n",
       " 'also': 0.0,\n",
       " 'sc': 0.0,\n",
       " 'ings': 0.0,\n",
       " 'You': 0.0,\n",
       " 'ón': 0.0,\n",
       " 'kn': 0.0,\n",
       " '();': 0.0,\n",
       " 'were': 0.0,\n",
       " 'ss': 0.0,\n",
       " 'Question': 0.0,\n",
       " 'ise': 0.0,\n",
       " 'they': 0.0,\n",
       " 'De': 0.0,\n",
       " 'ond': 0.0,\n",
       " 'sol': 0.0,\n",
       " 'fol': 0.0,\n",
       " 'more': 0.0,\n",
       " 'her': 0.0,\n",
       " 'é': 0.0,\n",
       " 'atch': 0.0,\n",
       " 'fter': 0.0,\n",
       " 'cre': 0.0,\n",
       " 'lock': 0.0,\n",
       " 'tring': 0.0,\n",
       " 'This': 0.0,\n",
       " 'ze': 0.0,\n",
       " 'ado': 0.0,\n",
       " 'ull': 0.0,\n",
       " 'ger': 0.0,\n",
       " 'other': 0.0,\n",
       " 'Tags': 0.0,\n",
       " 'ution': 0.0,\n",
       " 'ict': 0.0,\n",
       " 'how': 0.0,\n",
       " 'Se': 0.0,\n",
       " 'che': 0.0,\n",
       " 'cript': 0.0,\n",
       " 'just': 0.0,\n",
       " 'pos': 0.0,\n",
       " 'ange': 0.0,\n",
       " 'ific': 0.0,\n",
       " 'ree': 0.0,\n",
       " '}}': 0.0,\n",
       " 'time': 0.0,\n",
       " 'ны': 0.0,\n",
       " 'file': 0.0,\n",
       " 'ark': 0.0,\n",
       " 'ical': 0.0,\n",
       " 'first': 0.0,\n",
       " 'В': 0.0,\n",
       " 'He': 0.0,\n",
       " 'ta': 0.0,\n",
       " 'ument': 0.0,\n",
       " 'ors': 0.0,\n",
       " 'lement': 0.0,\n",
       " 'rac': 0.0,\n",
       " 'does': 0.0,\n",
       " 'yn': 0.0,\n",
       " 'read': 0.0,\n",
       " 'ual': 0.0,\n",
       " 'Le': 0.0,\n",
       " 'ys': 0.0,\n",
       " 'num': 0.0,\n",
       " 'vel': 0.0,\n",
       " 'ди': 0.0,\n",
       " 'over': 0.0,\n",
       " 'dif': 0.0,\n",
       " 'ethod': 0.0,\n",
       " 'If': 0.0,\n",
       " 'spe': 0.0,\n",
       " 'ym': 0.0,\n",
       " 'them': 0.0,\n",
       " 'into': 0.0,\n",
       " '         ': 0.0,\n",
       " 'its': 0.0,\n",
       " 'ese': 0.0,\n",
       " 'ield': 0.0,\n",
       " 'public': 0.0,\n",
       " 'П': 0.0,\n",
       " 'den': 0.0,\n",
       " 'ystem': 0.0,\n",
       " '->': 0.0,\n",
       " 'fil': 0.0,\n",
       " 'name': 0.0,\n",
       " 'inal': 0.0,\n",
       " 'ample': 0.0,\n",
       " 'way': 0.0,\n",
       " 'ica': 0.0,\n",
       " 'во': 0.0,\n",
       " 'cess': 0.0,\n",
       " 'itt': 0.0,\n",
       " 'uch': 0.0,\n",
       " 'where': 0.0,\n",
       " 'ми': 0.0,\n",
       " 'org': 0.0,\n",
       " 'https': 0.0,\n",
       " 'vo': 0.0,\n",
       " 'ient': 0.0,\n",
       " 'ove': 0.0,\n",
       " 'value': 0.0,\n",
       " 'eng': 0.0,\n",
       " 'La': 0.0,\n",
       " '^{': 0.0,\n",
       " 'ref': 0.0,\n",
       " 'ied': 0.0,\n",
       " 'ER': 0.0,\n",
       " 'stat': 0.0,\n",
       " 'fig': 0.0,\n",
       " 'von': 0.0,\n",
       " 'inter': 0.0,\n",
       " 'roid': 0.0,\n",
       " 'ater': 0.0,\n",
       " 'their': 0.0,\n",
       " 'bet': 0.0,\n",
       " 'ein': 0.0,\n",
       " '}\\\\': 0.0,\n",
       " '\">': 0.0,\n",
       " 'sub': 0.0,\n",
       " 'don': 0.0,\n",
       " 'ty': 0.0,\n",
       " 'try': 0.0,\n",
       " 'Pro': 0.0,\n",
       " 'tra': 0.0,\n",
       " 'same': 0.0,\n",
       " 'ep': 0.0,\n",
       " 'two': 0.0,\n",
       " 'old': 0.0,\n",
       " 'let': 0.0,\n",
       " 'sim': 0.0,\n",
       " 'bre': 0.0,\n",
       " 'blem': 0.0,\n",
       " 'ey': 0.0,\n",
       " 'could': 0.0,\n",
       " 'cor': 0.0,\n",
       " 'acc': 0.0,\n",
       " 'ays': 0.0,\n",
       " 'urr': 0.0,\n",
       " 'si': 0.0,\n",
       " 'const': 0.0,\n",
       " 'ues': 0.0,\n",
       " '}$': 0.0,\n",
       " 'View': 0.0,\n",
       " 'som': 0.0,\n",
       " 'about': 0.0,\n",
       " 'land': 0.0,\n",
       " 'mer': 0.0,\n",
       " 'list': 0.0,\n",
       " 'cal': 0.0,\n",
       " 'import': 0.0,\n",
       " 'na': 0.0,\n",
       " '::': 0.0,\n",
       " 'who': 0.0,\n",
       " 'error': 0.0,\n",
       " 'ator': 0.0,\n",
       " 'ext': 0.0,\n",
       " 'been': 0.0,\n",
       " 'ér': 0.0,\n",
       " 'run': 0.0,\n",
       " '**': 0.0,\n",
       " 'К': 0.0,\n",
       " 'ular': 0.0,\n",
       " 'ause': 0.0,\n",
       " 'reg': 0.0,\n",
       " 'know': 0.0,\n",
       " 'see': 0.0,\n",
       " 'him': 0.0,\n",
       " 'ning': 0.0,\n",
       " 'за': 0.0,\n",
       " 'ates': 0.0,\n",
       " 'fore': 0.0,\n",
       " 'ions': 0.0,\n",
       " 'hel': 0.0,\n",
       " 'ute': 0.0,\n",
       " 'rem': 0.0,\n",
       " 'Mar': 0.0,\n",
       " 'ру': 0.0,\n",
       " 'vice': 0.0,\n",
       " 'irect': 0.0,\n",
       " 'ner': 0.0,\n",
       " 'under': 0.0,\n",
       " 'rib': 0.0,\n",
       " 'hr': 0.0,\n",
       " 'че': 0.0,\n",
       " 'As': 0.0,\n",
       " 'ember': 0.0,\n",
       " 'а': 0.0,\n",
       " 'att': 0.0,\n",
       " 'ina': 0.0,\n",
       " 'son': 0.0,\n",
       " 'follow': 0.0,\n",
       " 'Sch': 0.0,\n",
       " 'pect': 0.0,\n",
       " 'rel': 0.0,\n",
       " 'So': 0.0,\n",
       " 'look': 0.0,\n",
       " 'abel': 0.0,\n",
       " 'problem': 0.0,\n",
       " 'van': 0.0,\n",
       " 'strong': 0.0,\n",
       " 'co': 0.0,\n",
       " 'pon': 0.0,\n",
       " 'ca': 0.0,\n",
       " 'ada': 0.0,\n",
       " '\":': 0.0,\n",
       " 'cond': 0.0,\n",
       " 'amb': 0.0,\n",
       " '},': 0.0,\n",
       " 'quest': 0.0,\n",
       " 'aut': 0.0,\n",
       " 'result': 0.0,\n",
       " 'may': 0.0,\n",
       " 'http': 0.0,\n",
       " '):': 0.0,\n",
       " 'And': 0.0,\n",
       " 'red': 0.0,\n",
       " 'How': 0.0,\n",
       " 'ско': 0.0,\n",
       " 'oup': 0.0,\n",
       " 'ced': 0.0,\n",
       " 'type': 0.0,\n",
       " 'than': 0.0,\n",
       " 'cons': 0.0,\n",
       " 'uf': 0.0,\n",
       " 'ци': 0.0,\n",
       " 'question': 0.0,\n",
       " 'raph': 0.0,\n",
       " 'igh': 0.0,\n",
       " 'М': 0.0,\n",
       " 'ins': 0.0,\n",
       " 'da': 0.0,\n",
       " 'oh': 0.0,\n",
       " '=>': 0.0,\n",
       " 'riv': 0.0,\n",
       " 'ude': 0.0,\n",
       " 'For': 0.0,\n",
       " 'frac': 0.0,\n",
       " 'ма': 0.0,\n",
       " 'after': 0.0,\n",
       " '}{': 0.0,\n",
       " 'method': 0.0,\n",
       " '\")': 0.0,\n",
       " 'amp': 0.0,\n",
       " 'ash': 0.0,\n",
       " 'rec': 0.0,\n",
       " 'differ': 0.0,\n",
       " 'ON': 0.0,\n",
       " 'ax': 0.0,\n",
       " 'ament': 0.0,\n",
       " 'ource': 0.0,\n",
       " 'Con': 0.0,\n",
       " 'Name': 0.0,\n",
       " 'bec': 0.0,\n",
       " 'En': 0.0,\n",
       " 'aj': 0.0,\n",
       " 'gener': 0.0,\n",
       " 'IN': 0.0,\n",
       " 'ages': 0.0,\n",
       " 'loc': 0.0,\n",
       " 'fo': 0.0,\n",
       " 'br': 0.0,\n",
       " 'she': 0.0,\n",
       " 'una': 0.0,\n",
       " 'к': 0.0,\n",
       " 'eta': 0.0,\n",
       " 'log': 0.0,\n",
       " 'olog': 0.0,\n",
       " 'sur': 0.0,\n",
       " 'arg': 0.0,\n",
       " 'kt': 0.0,\n",
       " '(\\\\': 0.0,\n",
       " 'min': 0.0,\n",
       " 'line': 0.0,\n",
       " 'vari': 0.0,\n",
       " 'ся': 0.0,\n",
       " 'ics': 0.0,\n",
       " 'ня': 0.0,\n",
       " 'very': 0.0,\n",
       " 'object': 0.0,\n",
       " 'Id': 0.0,\n",
       " 'But': 0.0,\n",
       " 'case': 0.0,\n",
       " 'make': 0.0,\n",
       " 'pass': 0.0,\n",
       " 'сь': 0.0,\n",
       " 'ession': 0.0,\n",
       " 'net': 0.0,\n",
       " '.\"': 0.0,\n",
       " 'г': 0.0,\n",
       " 'är': 0.0,\n",
       " 'де': 0.0,\n",
       " 'ating': 0.0,\n",
       " 'ato': 0.0,\n",
       " 'ви': 0.0,\n",
       " 'Ex': 0.0,\n",
       " 'ля': 0.0,\n",
       " 'umn': 0.0,\n",
       " 'ста': 0.0,\n",
       " 'ative': 0.0,\n",
       " 'String': 0.0,\n",
       " 'los': 0.0,\n",
       " 'wn': 0.0,\n",
       " 'answer': 0.0,\n",
       " 'ents': 0.0,\n",
       " 'fe': 0.0,\n",
       " 'ince': 0.0,\n",
       " 'ni': 0.0,\n",
       " 'ider': 0.0,\n",
       " 'ows': 0.0,\n",
       " 'test': 0.0,\n",
       " 'here': 0.0,\n",
       " 'roll': 0.0,\n",
       " 'call': 0.0,\n",
       " 'ruct': 0.0,\n",
       " 'pol': 0.0,\n",
       " 'ait': 0.0,\n",
       " 'back': 0.0,\n",
       " 'ho': 0.0,\n",
       " 'ress': 0.0,\n",
       " 'ST': 0.0,\n",
       " 'ried': 0.0,\n",
       " 'date': 0.0,\n",
       " 'ет': 0.0,\n",
       " 'did': 0.0,\n",
       " 'ting': 0.0,\n",
       " 'El': 0.0,\n",
       " 'dem': 0.0,\n",
       " ')$': 0.0,\n",
       " 'ова': 0.0,\n",
       " 'urrent': 0.0,\n",
       " 'lace': 0.0,\n",
       " 'right': 0.0,\n",
       " 'ren': 0.0,\n",
       " 'each': 0.0,\n",
       " 'cy': 0.0,\n",
       " 'block': 0.0,\n",
       " '==': 0.0,\n",
       " 'ür': 0.0,\n",
       " 'por': 0.0,\n",
       " 'ask': 0.0,\n",
       " 'arch': 0.0,\n",
       " 'ames': 0.0,\n",
       " 'ча': 0.0,\n",
       " 'off': 0.0,\n",
       " 'find': 0.0,\n",
       " 'now': 0.0,\n",
       " 'ational': 0.0,\n",
       " 'dd': 0.0,\n",
       " 'ción': 0.0,\n",
       " 'А': 0.0,\n",
       " 'ault': 0.0,\n",
       " 'List': 0.0,\n",
       " 'urs': 0.0,\n",
       " 'ake': 0.0,\n",
       " 'ule': 0.0,\n",
       " 'point': 0.0,\n",
       " 'AT': 0.0,\n",
       " 'trans': 0.0,\n",
       " 'used': 0.0,\n",
       " 'ски': 0.0,\n",
       " 'ari': 0.0,\n",
       " 'LE': 0.0,\n",
       " 'eter': 0.0,\n",
       " 'oun': 0.0,\n",
       " 'ever': 0.0,\n",
       " 'self': 0.0,\n",
       " 'ined': 0.0,\n",
       " 'idth': 0.0,\n",
       " 'ux': 0.0,\n",
       " 'js': 0.0,\n",
       " 'such': 0.0,\n",
       " 'Is': 0.0,\n",
       " 'ée': 0.0,\n",
       " 'ful': 0.0,\n",
       " 'dist': 0.0,\n",
       " 'bu': 0.0,\n",
       " 'itemize': 0.0,\n",
       " 'Cont': 0.0,\n",
       " 'je': 0.0,\n",
       " 'си': 0.0,\n",
       " 'prov': 0.0,\n",
       " 'bb': 0.0,\n",
       " 'ward': 0.0,\n",
       " 'esent': 0.0,\n",
       " 'erson': 0.0,\n",
       " 'anks': 0.0,\n",
       " 'We': 0.0,\n",
       " 'ka': 0.0,\n",
       " 'rop': 0.0,\n",
       " 'atur': 0.0,\n",
       " 'als': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(probsprobs[5890].cpu()),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probsprobs[5890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs['lying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{token: prob for token, prob in probs.items() if prob > 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lying'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(5890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying to SUNY Brockport is easy! You can start\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output['sequences'][0]).split(\"[/INST]\\n\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
