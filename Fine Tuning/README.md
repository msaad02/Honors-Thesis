
# Questions

## traditional LoRA?
example on falcon model: https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing

## How to finetune. Can you finetune GGML/GPTQ models?


## Combining LoRA with model to 1 model.
https://huggingface.co/TheBloke/guanaco-65B-GPTQ/discussions/2


## How to quantize a model to GGML/GPTQ format?
...




# About QLoRA
https://arxiv.org/pdf/2305.14314.pdf research paper
https://github.com/artidoro/qlora github repo


# Xturing??? Might be worth looking in to
https://github.com/stochasticai/xTuring/tree/main
example finetune with xturing: https://colab.research.google.com/drive/1SQUXq1AMZPSLD4mk3A3swUIc6Y2dclme?usp=sharing

