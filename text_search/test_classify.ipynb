{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_classifier import QuestionClassifier\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class QuestionClassifierWrapper:\n",
    "    \"Gets a question and using the probability output returns the exact places to do text retrieval from.\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            main_categorization_model_dir: str = \"model\",\n",
    "            subcategorization_model_dir: str = \"subcat_models/\"\n",
    "        ):\n",
    "        self.categorized_data = load_dataset(\"msaad02/categorized-data\", split=\"train\").to_pandas()\n",
    "        self.main_classifier = QuestionClassifier(model_dir=main_categorization_model_dir)\n",
    "        self.reranker_model = SentenceTransformer('msmarco-distilbert-base-v4', device='cuda')\n",
    "        self.subcategory_classifiers = {}\n",
    "        for subcat in os.listdir(subcategorization_model_dir):\n",
    "            self.subcategory_classifiers[subcat] = QuestionClassifier(subcategorization_model_dir + subcat)\n",
    "\n",
    "    def _predict(self, question: str, return_probabilities: bool = False):\n",
    "        \"Raw interface between the classifier and the user.\"\n",
    "        prediction = {}\n",
    "        if return_probabilities:\n",
    "            prediction['category'], prediction['main_probs'] = self.main_classifier.predict(question, True)\n",
    "        else:\n",
    "            prediction['category'] = self.main_classifier.predict(question)\n",
    "\n",
    "        if prediction['category'] in self.subcategory_classifiers:\n",
    "            subcategory_classifier = self.subcategory_classifiers[prediction['category']]\n",
    "\n",
    "            if return_probabilities:\n",
    "                prediction['subcategory'], prediction['sub_probs'] = subcategory_classifier.predict(question, True)\n",
    "            else:\n",
    "                prediction['subcategory'] = subcategory_classifier.predict(question)\n",
    "        return prediction\n",
    "    \n",
    "    def _get_text_retrieval_places(self, question: str):\n",
    "        \"\"\"\n",
    "        High level interface between the classifier and the user. Tells us where to do text retrieval from. Based on the probability output of the categorization models.\n",
    "\n",
    "        It does this by returning the top categories with confidence > 0.2 of the highest probability category. (I refer to confidence as the model's probability output.)\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                'main_categories': [str],\n",
    "                'subcategories': [str]\n",
    "            }\n",
    "        \"\"\"\n",
    "        prediction = self._predict(question, True)\n",
    "\n",
    "        # main category\n",
    "        main_cat_probs_df = pd.DataFrame(\n",
    "            [(category, prob) for category, prob in prediction['main_probs'].items()], \n",
    "            columns=['category', 'probability']\n",
    "        ).sort_values(by='probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # Use all categories at the top within 0.2 of the best category\n",
    "\n",
    "        # Highest category probability\n",
    "        max_main_prob = main_cat_probs_df['probability'][0]\n",
    "\n",
    "        # Categories within 0.2 of the highest category\n",
    "        main_categories_to_use = main_cat_probs_df[main_cat_probs_df['probability'] > max_main_prob - 0.2]['category'].tolist()\n",
    "\n",
    "        if 'sub_probs' in prediction.keys():\n",
    "            subcategory_probs_df = pd.DataFrame(\n",
    "                [(category, prob) for category, prob in prediction['sub_probs'].items()], \n",
    "                columns=['category', 'probability']\n",
    "            ).sort_values(by='probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "            # Highest subcategory probability\n",
    "            max_sub_prob = subcategory_probs_df['probability'][0]\n",
    "\n",
    "            # Subcategories within 0.2 of the highest subcategory\n",
    "            subcategories_to_use = subcategory_probs_df[subcategory_probs_df['probability'] > max_sub_prob - 0.2]['category'].tolist()\n",
    "\n",
    "        text_retreival_places = {\n",
    "            'main_categories': main_categories_to_use,\n",
    "            'subcategories': subcategories_to_use if 'sub_probs' in prediction.keys() else []\n",
    "        }\n",
    "\n",
    "        return text_retreival_places\n",
    "\n",
    "    def retreive_text(self, question: str, top_n: int = 3):\n",
    "        \"Retrieves text using the text retrieval places.\"\n",
    "\n",
    "        text_retreival_places = self._get_text_retrieval_places(question)\n",
    "        main_categories_to_use = text_retreival_places['main_categories']\n",
    "        subcategories_to_use = text_retreival_places['subcategories']\n",
    "                \n",
    "        filtered_catgory_df = self.categorized_data[self.categorized_data['category'].isin(main_categories_to_use)]\n",
    "        if subcategories_to_use != []:\n",
    "            filtered_catgory_df = filtered_catgory_df[filtered_catgory_df['subcategory'].isin(subcategories_to_use)]\n",
    "\n",
    "        data_to_embed = filtered_catgory_df['data'].to_list()\n",
    "\n",
    "        query_embedding = self.reranker_model.encode(question)\n",
    "        passage_embedding = self.reranker_model.encode(data_to_embed)\n",
    "\n",
    "\n",
    "        return text_retreival_places, util.cos_sim(query_embedding, passage_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = QuestionClassifierWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = classifier.retreive_text(\"How can I apply?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'main_categories': ['graduate',\n",
       "   'support',\n",
       "   'life',\n",
       "   'academics',\n",
       "   'library',\n",
       "   'admissions',\n",
       "   'about',\n",
       "   'bsg',\n",
       "   'alumni',\n",
       "   'scholarships-aid',\n",
       "   'live'],\n",
       "  'subcategories': []},\n",
       " tensor([[-0.0400,  0.0268, -0.1078,  ..., -0.0432, -0.0545, -0.1131]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradio_predict(question):\n",
    "#     return classifier.get_text_retrieval_places(question)\n",
    "\n",
    "# import gradio as gr\n",
    "\n",
    "# # output json\n",
    "# demo = gr.Interface(fn=gradio_predict, inputs=\"text\", outputs=\"json\")\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch(share=True)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
