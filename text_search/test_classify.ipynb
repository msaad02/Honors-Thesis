{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_classifier import QuestionClassifier\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class QuestionClassifierWrapper:\n",
    "    \"Gets a question and using the probability output returns the exact places to do text retrieval from.\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            main_categorization_model_dir: str = \"model\",\n",
    "            subcategorization_model_dir: str = \"subcat_models/\"\n",
    "        ):\n",
    "        self.categorized_data = load_dataset(\"msaad02/categorized-data\", split=\"train\").to_pandas()\n",
    "        self.main_classifier = QuestionClassifier(model_dir=main_categorization_model_dir)\n",
    "        self.reranker_model = SentenceTransformer('msmarco-distilbert-base-v4', device='cuda')\n",
    "        self.subcategory_classifiers = {}\n",
    "        for subcat in os.listdir(subcategorization_model_dir):\n",
    "            self.subcategory_classifiers[subcat] = QuestionClassifier(subcategorization_model_dir + subcat)\n",
    "\n",
    "    def _predict(self, question: str, return_probabilities: bool = False):\n",
    "        \"Raw interface between the classifier and the user.\"\n",
    "        prediction = {}\n",
    "        if return_probabilities:\n",
    "            prediction['category'], prediction['main_probs'] = self.main_classifier.predict(question, True)\n",
    "        else:\n",
    "            prediction['category'] = self.main_classifier.predict(question)\n",
    "\n",
    "        if prediction['category'] in self.subcategory_classifiers:\n",
    "            subcategory_classifier = self.subcategory_classifiers[prediction['category']]\n",
    "\n",
    "            if return_probabilities:\n",
    "                prediction['subcategory'], prediction['sub_probs'] = subcategory_classifier.predict(question, True)\n",
    "            else:\n",
    "                prediction['subcategory'] = subcategory_classifier.predict(question)\n",
    "        return prediction\n",
    "    \n",
    "    def _get_text_retrieval_places(self, question: str):\n",
    "        \"\"\"\n",
    "        High level interface between the classifier and the user. Tells us where to do text retrieval from. Based on the probability output of the categorization models.\n",
    "\n",
    "        It does this by returning the top categories with confidence > 0.2 of the highest probability category. (I refer to confidence as the model's probability output.)\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                'main_categories': [str],\n",
    "                'subcategories': [str]\n",
    "            }\n",
    "        \"\"\"\n",
    "        prediction = self._predict(question, True)\n",
    "\n",
    "        # main category\n",
    "        main_cat_probs_df = pd.DataFrame(\n",
    "            [(category, prob) for category, prob in prediction['main_probs'].items()], \n",
    "            columns=['category', 'probability']\n",
    "        ).sort_values(by='probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # Use all categories at the top within 0.2 of the best category\n",
    "\n",
    "        # Highest category probability\n",
    "        max_main_prob = main_cat_probs_df['probability'][0]\n",
    "\n",
    "        # Categories within 0.2 of the highest category\n",
    "        main_categories_to_use = main_cat_probs_df[main_cat_probs_df['probability'] > max_main_prob - 0.2]['category'].tolist()\n",
    "\n",
    "        if 'sub_probs' in prediction.keys():\n",
    "            subcategory_probs_df = pd.DataFrame(\n",
    "                [(category, prob) for category, prob in prediction['sub_probs'].items()], \n",
    "                columns=['category', 'probability']\n",
    "            ).sort_values(by='probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "            # Highest subcategory probability\n",
    "            max_sub_prob = subcategory_probs_df['probability'][0]\n",
    "\n",
    "            # Subcategories within 0.2 of the highest subcategory\n",
    "            subcategories_to_use = subcategory_probs_df[subcategory_probs_df['probability'] > max_sub_prob - 0.2]['category'].tolist()\n",
    "\n",
    "        text_retreival_places = {\n",
    "            'main_categories': main_categories_to_use,\n",
    "            'subcategories': subcategories_to_use if 'sub_probs' in prediction.keys() else []\n",
    "        }\n",
    "\n",
    "        return text_retreival_places\n",
    "\n",
    "    def retreive_text(self, question: str, top_n: int = 3):\n",
    "        \"Retrieves text using the text retrieval places.\"\n",
    "\n",
    "        text_retreival_places = self._get_text_retrieval_places(question)\n",
    "        main_categories_to_use = text_retreival_places['main_categories']\n",
    "        subcategories_to_use = text_retreival_places['subcategories']\n",
    "                \n",
    "        filtered_catgory_df = self.categorized_data[self.categorized_data['category'].isin(main_categories_to_use)]\n",
    "        if subcategories_to_use != []:\n",
    "            filtered_catgory_df = filtered_catgory_df[filtered_catgory_df['subcategory'].isin(subcategories_to_use)]\n",
    "\n",
    "        data_to_embed = filtered_catgory_df['data'].to_list()\n",
    "\n",
    "        query_embedding = self.reranker_model.encode(question)\n",
    "        passage_embedding = self.reranker_model.encode(data_to_embed)\n",
    "\n",
    "\n",
    "        return text_retreival_places, filtered_catgory_df, util.cos_sim(query_embedding, passage_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = QuestionClassifierWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = classifier.retreive_text(\"How can I apply?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16283/1501862640.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['similarity'] = sim[2][0]\n"
     ]
    }
   ],
   "source": [
    "df['similarity'] = sim[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764     International Admissions\\nFind out what you ne...\n",
       "2511    Advertising and Sponsorship\\n-\\nProof of ad is...\n",
       "1365    Application Qualifications\\n- First-time stude...\n",
       "2542    Affirming enrollment is necessary for loan def...\n",
       "500     All majors and certification programs offered ...\n",
       "1316    Participate in your own learning outcomes to b...\n",
       "768     Choose Your Application\\nSUNY Brockport operat...\n",
       "1477    How to Apply\\nThis is a multi-step application...\n",
       "2130    Financial Aid Requirements\\nWhere do I Start?\\...\n",
       "1430    Incoming Undergraduate First Year (freshmen) a...\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='similarity', ascending=False)['data'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0400,  0.0268, -0.1078,  ..., -0.0432, -0.0545, -0.1131]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradio_predict(question):\n",
    "#     return classifier.get_text_retrieval_places(question)\n",
    "\n",
    "# import gradio as gr\n",
    "\n",
    "# # output json\n",
    "# demo = gr.Interface(fn=gradio_predict, inputs=\"text\", outputs=\"json\")\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch(share=True)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
