{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "This is again following the tutorial on tensorflow's website. Did a lot of digging to find simpler implementations but it seems breaking things down in the following way is actually the most popular way to do it. Things may be better anyway since breaking it down makes learning easier. \n",
    "\n",
    "I plan to go slowly through this part and spend about a day with it to make sure I understand it. However, it's worth mentioning that this should be plug and play based on the same data pipeline I defined for the RNN in my original notebook \"follow-tf-tutorial.ipynb\". Note that the grand majority of this code is copy-pasted from the tutorial, including their comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Installing tensorflow_datasets and tensorflow_text updated tf to 2.13.0 from 12.2.1, if it breaks revert and find correct versions\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # stop showing tensorflow logs...\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check GPU is being used. Prints [] if not\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "\n",
    "# Prevent tensorflow from allocating all GPU memory at once\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) # Nice!\n",
    "\n",
    "\n",
    "# From tf_dataset.py in scratch-model, this gets the tf data pipeline\n",
    "from tf_dataset import get_datasets\n",
    "\n",
    "# MODEL PARAMS: These are roughly the same parameters as used in the original transformer paper.\n",
    "BATCH_SIZE = 64        \n",
    "EPOCHS = 25             # What we used for transformer_v1\n",
    "NUM_LAYERS = 6          # 4 \n",
    "D_MODEL = 512           # 128\n",
    "DFF = 2048              # 512\n",
    "NUM_HEADS = 8           # 8\n",
    "DROPOUT_RATE = 0.1      # 0.1\n",
    "\n",
    "save_dir = './models/transformer_v2'\n",
    "\n",
    "train_ds, val_ds, text_processor = get_datasets(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So use this to create a `PositionEmbedding` layer that looks-up a token's embedding vector and adds the position vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The [original paper](https://arxiv.org/pdf/1706.03762.pdf), section 3.4 and 5.1, uses a single tokenizer and weight matrix for both the source and target languages. This tutorial uses two separate tokenizers and weight matrices.\n",
    "\n",
    "---\n",
    "<span style=\"font-size:24px; color:lightblue\">Matt Notes</span>\n",
    "\n",
    "<span style=\"color:lightblue\">For my implementation I'm going back to the single tokenizer and weight matrix, since both my context and target is english with mostly the same vocabulary. The only reason to not do it in this way is if the vocabularies are quite different, which in the case of language translation (like this tutorial does) is the case.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "  \n",
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created the Transformer encoder and decoder, it's time to build the Transformer model and train it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "To keep this example small and relatively fast, the number of layers (`num_layers`), the dimensionality of the embeddings (`d_model`), and the internal dimensionality of the `FeedForward` layer (`dff`) have been reduced.\n",
    "\n",
    "The base model described in the original Transformer paper used `num_layers=6`, `d_model=512`, and `dff=2048`.\n",
    "\n",
    "The number of self-attention heads remains the same (`num_heads=8`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dff=DFF,\n",
    "    input_vocab_size=5000,  # This is the vocab size used for all the datasets.\n",
    "    target_vocab_size=5000,\n",
    "    dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "It's time to prepare the model and start training it.\n",
    "\n",
    "### Set up the optimizer\n",
    "\n",
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the optimizer (in this example it's `tf.keras.optimizers.Adam`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, \n",
    "    beta_1=0.9, \n",
    "    beta_2=0.98,\n",
    "    epsilon=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the custom learning rate scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the loss and metrics\n",
    "\n",
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss. Use the cross-entropy loss function (`tf.keras.losses.SparseCategoricalCrossentropy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "With all the components ready, configure the training procedure using `model.compile`, and then run it with `model.fit`:\n",
    "\n",
    "Note: This takes about an hour to train in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "89/89 [==============================] - 64s 408ms/step - loss: 7.6843 - masked_accuracy: 0.0695 - val_loss: 6.8700 - val_masked_accuracy: 0.1388\n",
      "Epoch 2/25\n",
      "89/89 [==============================] - 30s 335ms/step - loss: 6.3176 - masked_accuracy: 0.1818 - val_loss: 5.6168 - val_masked_accuracy: 0.2217\n",
      "Epoch 3/25\n",
      "89/89 [==============================] - 29s 329ms/step - loss: 5.2496 - masked_accuracy: 0.2591 - val_loss: 4.7051 - val_masked_accuracy: 0.3061\n",
      "Epoch 4/25\n",
      "89/89 [==============================] - 30s 332ms/step - loss: 4.5186 - masked_accuracy: 0.3297 - val_loss: 4.1158 - val_masked_accuracy: 0.3639\n",
      "Epoch 5/25\n",
      "89/89 [==============================] - 28s 314ms/step - loss: 3.9919 - masked_accuracy: 0.3867 - val_loss: 3.6831 - val_masked_accuracy: 0.4192\n",
      "Epoch 6/25\n",
      "89/89 [==============================] - 29s 321ms/step - loss: 3.5616 - masked_accuracy: 0.4352 - val_loss: 3.3475 - val_masked_accuracy: 0.4577\n",
      "Epoch 7/25\n",
      "89/89 [==============================] - 29s 321ms/step - loss: 3.2061 - masked_accuracy: 0.4743 - val_loss: 3.1083 - val_masked_accuracy: 0.4825\n",
      "Epoch 8/25\n",
      "89/89 [==============================] - 28s 317ms/step - loss: 2.9051 - masked_accuracy: 0.5056 - val_loss: 2.9126 - val_masked_accuracy: 0.5009\n",
      "Epoch 9/25\n",
      "89/89 [==============================] - 29s 326ms/step - loss: 2.6386 - masked_accuracy: 0.5360 - val_loss: 2.7514 - val_masked_accuracy: 0.5238\n",
      "Epoch 10/25\n",
      "89/89 [==============================] - 29s 321ms/step - loss: 2.3935 - masked_accuracy: 0.5659 - val_loss: 2.6603 - val_masked_accuracy: 0.5285\n",
      "Epoch 11/25\n",
      "89/89 [==============================] - 29s 326ms/step - loss: 2.1806 - masked_accuracy: 0.5932 - val_loss: 2.5408 - val_masked_accuracy: 0.5398\n",
      "Epoch 12/25\n",
      "89/89 [==============================] - 29s 327ms/step - loss: 1.9729 - masked_accuracy: 0.6193 - val_loss: 2.5127 - val_masked_accuracy: 0.5491\n",
      "Epoch 13/25\n",
      "89/89 [==============================] - 29s 331ms/step - loss: 1.7831 - masked_accuracy: 0.6456 - val_loss: 2.4662 - val_masked_accuracy: 0.5580\n",
      "Epoch 14/25\n",
      "89/89 [==============================] - 30s 333ms/step - loss: 1.6049 - masked_accuracy: 0.6717 - val_loss: 2.4156 - val_masked_accuracy: 0.5675\n",
      "Epoch 15/25\n",
      "89/89 [==============================] - 30s 335ms/step - loss: 1.4383 - masked_accuracy: 0.6969 - val_loss: 2.3942 - val_masked_accuracy: 0.5737\n",
      "Epoch 16/25\n",
      "89/89 [==============================] - 30s 334ms/step - loss: 1.2852 - masked_accuracy: 0.7210 - val_loss: 2.4138 - val_masked_accuracy: 0.5782\n",
      "Epoch 17/25\n",
      "89/89 [==============================] - 29s 329ms/step - loss: 1.1369 - masked_accuracy: 0.7463 - val_loss: 2.4004 - val_masked_accuracy: 0.5831\n",
      "Epoch 18/25\n",
      "89/89 [==============================] - 28s 318ms/step - loss: 1.0066 - masked_accuracy: 0.7703 - val_loss: 2.4448 - val_masked_accuracy: 0.5811\n",
      "Epoch 19/25\n",
      "89/89 [==============================] - 29s 319ms/step - loss: 0.8927 - masked_accuracy: 0.7908 - val_loss: 2.4674 - val_masked_accuracy: 0.5781\n",
      "Epoch 20/25\n",
      "89/89 [==============================] - 28s 320ms/step - loss: 0.7964 - masked_accuracy: 0.8095 - val_loss: 2.4960 - val_masked_accuracy: 0.5818\n",
      "Epoch 21/25\n",
      "89/89 [==============================] - 29s 328ms/step - loss: 0.7084 - masked_accuracy: 0.8270 - val_loss: 2.5138 - val_masked_accuracy: 0.5768\n",
      "Epoch 22/25\n",
      "89/89 [==============================] - 28s 310ms/step - loss: 0.6276 - masked_accuracy: 0.8443 - val_loss: 2.5879 - val_masked_accuracy: 0.5765\n",
      "Epoch 23/25\n",
      "89/89 [==============================] - 29s 328ms/step - loss: 0.5803 - masked_accuracy: 0.8530 - val_loss: 2.6121 - val_masked_accuracy: 0.5772\n",
      "Epoch 24/25\n",
      "89/89 [==============================] - 30s 335ms/step - loss: 0.5256 - masked_accuracy: 0.8660 - val_loss: 2.6406 - val_masked_accuracy: 0.5814\n",
      "Epoch 25/25\n",
      "89/89 [==============================] - 29s 324ms/step - loss: 0.4998 - masked_accuracy: 0.8699 - val_loss: 2.6680 - val_masked_accuracy: 0.5796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb29c59a610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  65579008  \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  115993600 \n",
      "                                                                 \n",
      " dense_24 (Dense)            multiple                  2565000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,137,608\n",
      "Trainable params: 184,137,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary() # 9 Million Parameter Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference\n",
    "\n",
    "You can now test the model by performing a translation. The following steps are used for inference:\n",
    "\n",
    "* Encode the input sentence using the tokenizer. This is the encoder input.\n",
    "* The decoder input is initialized to the `[START]` token.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Concatenate the predicted token to the decoder input and pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next token based on the previous tokens it predicted.\n",
    "\n",
    "Note: The model is optimized for _efficient training_ and makes a next-token prediction for each token in the output simultaneously. This is redundant during inference, and only the last prediction is used.  This model can be made more efficient for inference if you only calculate the last prediction when running in inference mode (`training=False`).\n",
    "\n",
    "Define the `QuestionAnswering` class by subclassing `tf.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = text_processor.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 256\n",
    "\n",
    "class QuestionAnswering(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    sentence = tf.convert_to_tensor([sentence])\n",
    "\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    # sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "    sentence = self.tokenizers(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    vocab_tf = tf.constant(vocab)\n",
    "\n",
    "    text = tf.strings.reduce_join(tf.map_fn(lambda x: vocab_tf[x], tf.squeeze(output), dtype=tf.string), separator=\" \")\n",
    "    tokens = output\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This function uses an unrolled loop, not a dynamic loop. It generates `MAX_TOKENS` on every call. Refer to the [NMT with attention](nmt_with_attention.ipynb) tutorial for an example implementation with a dynamic loop, which can be much more efficient.\n",
    "\n",
    "Create an instance of this `Translator` class, and try it out a few times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionAnswerer = QuestionAnswering(text_processor, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Formatting for responses\n",
    "def format_output(sentence):\n",
    "    # Strip spaces around punctuation\n",
    "    sentence = re.sub(r'\\s+([.,!?])', r'\\1', str(sentence.numpy()))\n",
    "\n",
    "    # Capitalize known proper nouns\n",
    "    known_proper_nouns = {\"suny\": \"SUNY\", \"brockport\": \"Brockport\", \"computer\": \"Computer\", \"science\": \"Science\"}\n",
    "    for key, value in known_proper_nouns.items():\n",
    "        sentence = sentence.replace(key, value)\n",
    "\n",
    "    # Capitalize the first letter of the sentence\n",
    "    sentence = sentence[0].upper() + sentence[1:]\n",
    "\n",
    "    return sentence\n",
    "\n",
    "# Print it out nicely\n",
    "def print_translation(sentence, translated_text):\n",
    "  print(f'Input: {sentence}')\n",
    "  print(f'Prediction: {translated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How many programs does Brockport offer?\n",
      "Prediction: b'[START] brockport offers over minors . [END]'\n"
     ]
    }
   ],
   "source": [
    "sentence = 'How many programs does Brockport offer?'\n",
    "\n",
    "translated_text, tokens, attention_weights = questionAnswerer(sentence)\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Are SAT scores required?\n",
      "Prediction: b'[START] no , optional scores are not typically not acceptable and sat or act scores . [END]'\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Are SAT scores required?'\n",
    "\n",
    "translated_text, tokens, attention_weights = questionAnswerer(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How can I apply for financial aid?\n",
      "Prediction: b'[START] you can apply for financial aid through the financial aid office . [END]'\n"
     ]
    }
   ],
   "source": [
    "sentence = 'How can I apply for financial aid?'\n",
    "\n",
    "translated_text, tokens, attention_weights = questionAnswerer(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What concentrations are available for Computer Science?\n",
      "Prediction: b'[START] computer science systems [UNK] are available for computer science , such as computer information systems , science , and the computer information systems . [END]'\n"
     ]
    }
   ],
   "source": [
    "sentence = 'What concentrations are available for Computer Science?'\n",
    "\n",
    "translated_text, tokens, attention_weights = questionAnswerer(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What limitations are there for non-matriculated students if they choose to enroll at a later date?\n",
      "Prediction: b'[START] nonmatriculated students choose to enroll at a later date , they are subject to all changes in the course catalog . [END]'\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What limitations are there for non-matriculated students if they choose to enroll at a later date?\"\n",
    "\n",
    "translated_text, tokens, attention_weights = questionAnswerer(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model\n",
    "\n",
    "You have tested the model and the inference is working. Next, you can export it as a `tf.saved_model`. To learn about saving and loading a model in the SavedModel format, use [this guide](https://www.tensorflow.org/guide/saved_model).\n",
    "\n",
    "Create a class called `ExportTranslator` by subclassing the `tf.Module` subclass with a `tf.function` on the `__call__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportTranslator(tf.Module):\n",
    "  def __init__(self, translator):\n",
    "    self.translator = translator\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def __call__(self, sentence):\n",
    "    # sentence = tf.constant([sentence])\n",
    "    result, tokens, attention_weights = self.translator(sentence, max_length=MAX_TOKENS)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above `tf.function` only the output sentence is returned. Thanks to the [non-strict execution](https://tensorflow.org/guide/intro_to_graphs) in `tf.function` any unnecessary values are never computed.\n",
    "\n",
    "Wrap `translator` in the newly created `ExportTranslator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionAnswerer = ExportTranslator(questionAnswerer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note to self:\n",
    "\n",
    "Need to figure out what's causing this error and fix it. Then I can save the model and load it in any other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'[START] you can apply to suny brockport by visiting their website and filling out the application . [END]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionAnswerer('How can I apply?').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(questionAnswerer, export_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading in the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[START] you can apply to suny brockport by visiting their website and filling out the application . [END]'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.saved_model.load('./models/transformer_v2')\n",
    "model(\"How can I apply?\").numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
