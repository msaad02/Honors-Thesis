{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 16:53:05.905577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 16:53:05.905719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 16:53:06.147392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-12 16:53:06.147539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_datasets\n",
    "_, _, text_vect= get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vect([''])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: text_processor/assets\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([text_vect])\n",
    "model.save(\"text_processor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "text_vect = tf.keras.models.load_model(\"text_processor\").layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f8dc83e7d50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 16:46:41.703967: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 16:46:41.726890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 16:46:42.193767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(name=\"text_standardization\")\n",
    "def tf_lower_and_split_punct(text):\n",
    "    \"Text standardization function. Tries to make things uniform.\"\n",
    "    text = tf.strings.lower(text) # Lowercase everything\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '') # Keep space, a to z and punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ') # Add spaces around punctuation.\n",
    "    text = tf.strings.strip(text) # Strip whitespace.\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ') # Add start and end token\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from inference import ScratchModel\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model = ScratchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I apply to SUNY Brockport?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token)\n",
      "File \u001b[0;32m~/workspace/honors-thesis/scratch_model/inference.py:111\u001b[0m, in \u001b[0;36mScratchModel.__call__\u001b[0;34m(self, question, max_tokens, stream)\u001b[0m\n\u001b[1;32m    108\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_processor(question)\u001b[38;5;241m.\u001b[39mto_tensor()\n\u001b[1;32m    110\u001b[0m start_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_processor([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 111\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mstart_end\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[tf\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    112\u001b[0m end \u001b[38;5;241m=\u001b[39m start_end[\u001b[38;5;241m1\u001b[39m][tf\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    114\u001b[0m output_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensorArray(dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dynamic_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "question = \"How can I apply to SUNY Brockport?\"\n",
    "\n",
    "generator = model(question, stream=True)\n",
    "\n",
    "for token in generator:\n",
    "    print(token)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./models/transformer_v4/\" + \"text_processor\")\n",
    "\n",
    "# Retrieve the TextVectorization layer\n",
    "loaded_text_processor = loaded_model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 16:59:47.879694: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 16:59:47.902993: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 16:59:48.377749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-12 16:59:49.889080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:49.900924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:49.900957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:49.903166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:49.903194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:49.903206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:50.028979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:50.029027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:50.029031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-12 16:59:50.029048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 16:59:50.029070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-01-12 16:59:50.671963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 16:59:50.672103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 16:59:50.865198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 16:59:50.865327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # stop showing tensorflow logs\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")\n",
    "dataset = dataset['train'].to_pandas()\n",
    "\n",
    "# Note that the prompt is never used in the dataset, but it is included \n",
    "# here as an artifact from the original implementation of the scratch model\n",
    "prompt = lambda question, answer: f\"\"\"Below is an inquiery related to SUNY Brockport - from academics, admissions, and faculty support to student life. Prioritize accuracy and brevity.\\n\\n### Instruction:\\n{question}\\n\\n### Response:\\n{answer}\"\"\"\n",
    "\n",
    "dataset = [prompt(question, answer) for question, answer in zip(dataset['question'], dataset['answer'])]\n",
    "\n",
    "def split_input_output(s):\n",
    "    \"\"\"\n",
    "    Splits a string into a question and answer pair\n",
    "    \"\"\"\n",
    "    output_split = s.split('\\n\\n### Response:\\n')\n",
    "    input_split = output_split[0].split('### Instruction:\\n')[1]\n",
    "    return input_split, output_split[1]\n",
    "\n",
    "context_raw, target_raw = [list(t) for t in zip(*[split_input_output(string) for string in dataset])]\n",
    "\n",
    "# Add start and end tokens\n",
    "target_raw = [\"[START] \" + text + \" [END]\" for text in target_raw]\n",
    "\n",
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train_mask = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_context = np.array(context_raw)[is_train_mask]\n",
    "train_target = np.array(target_raw)[is_train_mask]\n",
    "\n",
    "val_context = np.array(context_raw)[~is_train_mask]\n",
    "val_target = np.array(target_raw)[~is_train_mask]\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_context, train_target))\n",
    "    .shuffle(BUFFER_SIZE, seed=seed)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((val_context, val_target))\n",
    "    .shuffle(BUFFER_SIZE, seed=seed)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=MAX_VOCAB_SIZE,\n",
    "    ragged=True\n",
    ")\n",
    "\n",
    "text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "\n",
    "def process_text(context, target):\n",
    "    context = text_processor(context).to_tensor()\n",
    "    target  = text_processor(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (<tf.Tensor: shape=(64, 23), dtype=int64, numpy=\n",
      "array([[ 282,  884,    3, ...,    0,    0,    0],\n",
      "       [ 305,   22,    3, ...,    0,    0,    0],\n",
      "       [ 138,  884,    3, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  50, 2262, 4346, ...,    0,    0,    0],\n",
      "       [ 138,  370,  789, ...,    0,    0,    0],\n",
      "       [  22,  103,   49, ...,   30,    1,  349]])>, <tf.Tensor: shape=(64, 82), dtype=int64, numpy=\n",
      "array([[   7,    3,  647, ...,    0,    0,    0],\n",
      "       [   7,    9,   97, ...,    0,    0,    0],\n",
      "       [   7,    3, 1629, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   7,  208,    9, ...,    0,    0,    0],\n",
      "       [   7,    2,  161, ...,   57,    3,   66],\n",
      "       [   7,  127,  103, ...,    0,    0,    0]])>)\n",
      "Targets: tf.Tensor(\n",
      "[[   3  647 1029 ...    0    0    0]\n",
      " [   9   97   56 ...    0    0    0]\n",
      " [   3 1629  240 ...    0    0    0]\n",
      " ...\n",
      " [ 208    9 4346 ...    0    0    0]\n",
      " [   2  161    6 ...    3   66    8]\n",
      " [ 127  103   22 ...    0    0    0]], shape=(64, 82), dtype=int64)\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:02:54.384447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2024-01-12 17:02:54.384641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    }
   ],
   "source": [
    "for batch in val_ds.take(1):  # Adjust the number to how many batches you want to inspect\n",
    "    # Assuming each batch contains a tuple of (inputs, targets)\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(82,), dtype=int64, numpy=\n",
       "array([   3,  647, 1029,   10,  205,   23, 2170,   12,  657,    4,    1,\n",
       "         10,    6,  441,  130, 1375,    3,  383,  657,   31,   38, 2208,\n",
       "          3,  104,  141,    3,  364,  102,    9, 1029,   50, 1922,   41,\n",
       "       1345,    2,  657,    4,   10,  294,  732,   12,    3,  288, 1029,\n",
       "         14,   41,  112,    2,  657,   26,   91,    2,  184,    5,  868,\n",
       "        423,    9,   37,  159,    8,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:06:11.993472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 17:06:11.993611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 17:06:12.278709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-01-12 17:06:12.278848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [9248]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script creates a tensorflow dataset for the brockport-gpt-4-qa dataset to feed into the model.\n",
    "\n",
    "This also does some preprocessing of the data, such as adding start and end tokens, and standardizing the text.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # stop showing tensorflow logs\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")\n",
    "dataset = dataset['train'].to_pandas()\n",
    "\n",
    "# Note that the prompt is never used in the dataset, but it is included \n",
    "# here as an artifact from the original implementation of the scratch model\n",
    "prompt = lambda question, answer: f\"\"\"Below is an inquiery related to SUNY Brockport - from academics, admissions, and faculty support to student life. Prioritize accuracy and brevity.\\n\\n### Instruction:\\n{question}\\n\\n### Response:\\n{answer}\"\"\"\n",
    "\n",
    "dataset = [prompt(question, answer) for question, answer in zip(dataset['question'], dataset['answer'])]\n",
    "\n",
    "def split_input_output(s):\n",
    "    \"\"\"\n",
    "    Splits a string into a question and answer pair\n",
    "    \"\"\"\n",
    "    output_split = s.split('\\n\\n### Response:\\n')\n",
    "    input_split = output_split[0].split('### Instruction:\\n')[1]\n",
    "    return input_split, output_split[1]\n",
    "\n",
    "# @tf.keras.saving.register_keras_serializable(name=\"text_standardization\")\n",
    "@tf.keras.utils.register_keras_serializable(name=\"text_standardization\")\n",
    "def tf_lower_and_split_punct(text):\n",
    "    \"Text standardization function. Tries to make things uniform.\"\n",
    "    text = tf.strings.lower(text) # Lowercase everything\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '') # Keep space, a to z and punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ') # Add spaces around punctuation.\n",
    "    text = tf.strings.strip(text) # Strip whitespace.\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ') # Add start and end token\n",
    "    return text\n",
    "\n",
    "context_raw, target_raw = [list(t) for t in zip(*[split_input_output(string) for string in dataset])]\n",
    "\n",
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train_mask = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_context = np.array(context_raw)[is_train_mask]\n",
    "train_target = np.array(target_raw)[is_train_mask]\n",
    "\n",
    "val_context = np.array(context_raw)[~is_train_mask]\n",
    "val_target = np.array(target_raw)[~is_train_mask]\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_context, train_target))\n",
    "    .shuffle(BUFFER_SIZE, seed=seed)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((val_context, val_target))\n",
    "    .shuffle(BUFFER_SIZE, seed=seed)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=MAX_VOCAB_SIZE,\n",
    "    ragged=True\n",
    ")\n",
    "\n",
    "text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "\n",
    "def process_text(context, target):\n",
    "    context = text_processor(context).to_tensor()\n",
    "    target  = text_processor(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (<tf.Tensor: shape=(64, 27), dtype=int64, numpy=\n",
      "array([[   9,  286,  888, ...,    0,    0,    0],\n",
      "       [   9,  310,   25, ...,    0,    0,    0],\n",
      "       [   9,  141,  888, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   9,   53, 2236, ...,    0,    0,    0],\n",
      "       [   9,  141,  374, ...,    0,    0,    0],\n",
      "       [   9,   25,  106, ...,  354, 1568,   10]])>, <tf.Tensor: shape=(64, 92), dtype=int64, numpy=\n",
      "array([[   9,    5,  647, ...,    0,    0,    0],\n",
      "       [   9,   11,  100, ...,    0,    0,    0],\n",
      "       [   9,    5, 1621, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   9,  212,    2, ...,    0,    0,    0],\n",
      "       [   9,    4,  164, ...,    5,   69,   15],\n",
      "       [   9,  129,    2, ...,    0,    0,    0]])>)\n",
      "Targets: tf.Tensor(\n",
      "[[   5  647 1031 ...    0    0    0]\n",
      " [  11  100   59 ...    0    0    0]\n",
      " [   5 1621  244 ...    0    0    0]\n",
      " ...\n",
      " [ 212    2   11 ...    0    0    0]\n",
      " [   4  164    8 ...   69   15   10]\n",
      " [ 129    2  106 ...    0    0    0]], shape=(64, 92), dtype=int64)\n",
      "-----\n",
      "Inputs: (<tf.Tensor: shape=(64, 24), dtype=int64, numpy=\n",
      "array([[  9, 211,  19, ...,   0,   0,   0],\n",
      "       [  9,  19, 430, ...,   0,   0,   0],\n",
      "       [  9, 310,  42, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  9,   1, 194, ...,   0,   0,   0],\n",
      "       [  9,  19, 716, ...,   0,   0,   0],\n",
      "       [  9, 141,  19, ...,   0,   0,   0]])>, <tf.Tensor: shape=(64, 85), dtype=int64, numpy=\n",
      "array([[  9,  41,  14, ...,   0,   0,   0],\n",
      "       [  9, 683,  15, ...,   0,   0,   0],\n",
      "       [  9,  42, 195, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  9,  12,  54, ...,   0,   0,   0],\n",
      "       [  9,  64,  15, ...,   0,   0,   0],\n",
      "       [  9,  34,  41, ...,   0,   0,   0]])>)\n",
      "Targets: tf.Tensor(\n",
      "[[  41   14 1630 ...    0    0    0]\n",
      " [ 683   15  430 ...    0    0    0]\n",
      " [  42  195   20 ...    0    0    0]\n",
      " ...\n",
      " [  12   54   24 ...    0    0    0]\n",
      " [  64   15   34 ...    0    0    0]\n",
      " [  34   41 2876 ...    0    0    0]], shape=(64, 85), dtype=int64)\n",
      "-----\n",
      "Inputs: (<tf.Tensor: shape=(64, 24), dtype=int64, numpy=\n",
      "array([[   9,  141,   19, ...,    0,    0,    0],\n",
      "       [   9,   25,  106, ...,   10,    0,    0],\n",
      "       [   9,  141, 1281, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   9,  211,   19, ...,    0,    0,    0],\n",
      "       [   9,  141,   19, ...,    0,    0,    0],\n",
      "       [   9,  310, 3585, ...,    0,    0,    0]])>, <tf.Tensor: shape=(64, 90), dtype=int64, numpy=\n",
      "array([[   9,   50,  160, ...,    0,    0,    0],\n",
      "       [   9,   64,   15, ...,    0,    0,    0],\n",
      "       [   9,  615, 1339, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   9,    7,   19, ...,    0,    0,    0],\n",
      "       [   9,   50,  160, ...,    0,    0,    0],\n",
      "       [   9,   23,   21, ...,    0,    0,    0]])>)\n",
      "Targets: tf.Tensor(\n",
      "[[  50  160    4 ...    0    0    0]\n",
      " [  64   15    5 ...    0    0    0]\n",
      " [ 615 1339   12 ...    0    0    0]\n",
      " ...\n",
      " [   7   19  542 ...    0    0    0]\n",
      " [  50  160   41 ...    0    0    0]\n",
      " [  23   21 1747 ...    0    0    0]], shape=(64, 90), dtype=int64)\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:06:38.487070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2334]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-12 17:06:38.487306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    }
   ],
   "source": [
    "for batch in val_ds.take(3):  # Adjust the number to how many batches you want to inspect\n",
    "    # Assuming each batch contains a tuple of (inputs, targets)\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[9, 10]]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processor([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int64, numpy=\n",
       "array([   9,  141,   19,  716,  214,    5, 2760, 4156, 1266,   13,  776,\n",
       "       1280, 2760,   20,   23,   21, 1568,   10,    0,    0,    0,    0,\n",
       "          0,    0])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
