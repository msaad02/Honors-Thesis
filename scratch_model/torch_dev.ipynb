{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Are there any areas on campus where my service animal is not allowed?',\n",
       "        'SUNY Brockport is committed to ensuring the safety and well-being of all members of our community, including service animals. There are certain areas on campus where service animals may be restricted due to health, safety, or operational reasons. These can include food preparation areas, specific research labs, and other sensitive locations. If you need access to these areas, please contact the appropriate department representative and the ADA or Section 504 officer on campus to discuss your case.'],\n",
       "       ['Are there opportunities for internships or research practicums in the sociology program?',\n",
       "        \"Absolutely! Many of our sociology students complete internships or research practicums as part of their major. These hands-on experiences are a fantastic way to apply what you've learned in the classroom to real-world situations, and they can be incredibly valuable when you're starting your career or applying to graduate school.\"],\n",
       "       ['What can I expect during the individual interview for the RA position?',\n",
       "        \"During the individual interview, you'll meet with a combination of Residence Directors (RDs) and current RAs who will ask you questions focused on the RA position. This is your chance to express your interest in the role, discuss your understanding of the responsibilities, and share more about yourself. It's a great platform to let your enthusiasm and suitability for the position shine!\"],\n",
       "       ...,\n",
       "       ['How can I tell if a student group at SUNY Brockport is officially recognized?',\n",
       "        \"Great question! To determine if a student group is officially recognized, you can check the list of recognized student organizations on our website or contact the Student Union and Activities office at (585) 395-5646. They'll be happy to assist you in identifying legitimate groups!\"],\n",
       "       [\"Am I eligible to take WinterSession courses if I've been academically dismissed?\",\n",
       "        \"If you've been academically dismissed and have not been reinstated, or if you've been denied undergraduate admission at SUNY Brockport within the past year, you're not eligible to take WinterSession courses. However, if your situation changes, we encourage you to reach out to us for guidance on your next steps. We're here to help you succeed!\"],\n",
       "       ['How does experiential learning play a role in Delta College?',\n",
       "        'Experiential learning is a core aspect of the Delta College program. It integrates real-world experiences with classroom learning, providing students with practical applications of their studies through internships, community service, and other hands-on opportunities both locally and internationally.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset[['question', 'answer']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer, max_length=512):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.tokenizer(\n",
    "            '[START] ' + self.questions[idx] + ' [END]',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        answer = self.tokenizer(\n",
    "            '[START] ' + self.answers[idx] + ' [END]',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return question['input_ids'].squeeze(0), answer['input_ids'].squeeze(0)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch)\n",
    "    questions = pad_sequence(questions, batch_first=True, padding_value=0)\n",
    "    answers = pad_sequence(answers, batch_first=True, padding_value=0)\n",
    "    return questions, answers[:, :-1], answers[:, 1:]\n",
    "\n",
    "def get_datasets(tokenizer, batch_size=64):\n",
    "    dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")\n",
    "    dataset = dataset['train'].to_pandas()\n",
    "\n",
    "    context_raw = dataset['question'].to_list()\n",
    "    target_raw = dataset['answer'].to_list()\n",
    "\n",
    "    is_train_mask = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "    train_context = np.array(context_raw)[is_train_mask]\n",
    "    train_target = np.array(target_raw)[is_train_mask]\n",
    "\n",
    "    val_context = np.array(context_raw)[~is_train_mask]\n",
    "    val_target = np.array(target_raw)[~is_train_mask]\n",
    "\n",
    "    train_dataset = Seq2SeqDataset(train_context, train_target, tokenizer)\n",
    "    val_dataset = Seq2SeqDataset(val_context, val_target, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Assuming you're using a tokenizer compatible with your model, e.g., BERT-based\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_loader, val_loader = get_datasets(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, data, vocab, tokenizer):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        context = torch.tensor([self.vocab[token] for token in self.tokenizer(context)])\n",
    "        target = torch.tensor([self.vocab[token] for token in self.tokenizer(target)])\n",
    "        return context, target\n",
    "\n",
    "def collate_batch(batch):\n",
    "    contexts, targets = zip(*batch)\n",
    "    pad_idx = vocab['<pad>']\n",
    "    sos_idx = vocab['<sos>']\n",
    "    eos_idx = vocab['<eos>']\n",
    "\n",
    "    contexts = [torch.cat([torch.tensor([sos_idx]), context, torch.tensor([eos_idx])], dim=0) for context in contexts]\n",
    "    targets = [torch.cat([torch.tensor([sos_idx]), target, torch.tensor([eos_idx])], dim=0) for target in targets]\n",
    "\n",
    "    context_lens = torch.tensor([len(context) for context in contexts])\n",
    "    target_lens = torch.tensor([len(target) for target in targets])\n",
    "\n",
    "    contexts = pad_sequence(contexts, padding_value=pad_idx)\n",
    "    targets = pad_sequence(targets, padding_value=pad_idx)\n",
    "\n",
    "    return contexts, targets, context_lens, target_lens\n",
    "\n",
    "\n",
    "def build_vocab(data, tokenizer):\n",
    "    token_generator = (token for _, sent in data for token in tokenizer(sent))\n",
    "    return build_vocab_from_iterator(token_generator, specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"], special_first=True)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")['train'].to_pandas()\n",
    "\n",
    "# Create a list of tuples (context, target)\n",
    "data = list(zip(dataset['question'].tolist(), dataset['answer'].tolist()))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Randomly split data into train and validation\n",
    "split_idx = int(0.8 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "# Define tokenizer and vocabulary\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab(train_data + val_data, tokenizer)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Seq2SeqDataset(train_data, vocab, tokenizer)\n",
    "val_dataset = Seq2SeqDataset(val_data, vocab, tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'can', 'i', 'apply', '?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"How can I apply?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 13\n",
    "BATCH_SIZE = 64\n",
    "NUM_LAYERS = 6\n",
    "D_MODEL = 512\n",
    "DFF = 2048\n",
    "NUM_HEADS = 8\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "model = nn.Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NUM_HEADS,\n",
    "    num_encoder_layers=NUM_LAYERS,\n",
    "    num_decoder_layers=NUM_LAYERS,\n",
    "    dim_feedforward=DFF,\n",
    "    dropout=DROPOUT_RATE,\n",
    "    activation='relu',\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token what not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f6cc5d7dd87 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f6cc5d2e75f in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f6bb22418b4 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1dc5b (0x7f6c082a9c5b in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3dee7 (0x7f6c082c9ee7 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/_torchtext.so)\nframe #5: /home/msaad/miniconda3/envs/thesis/bin/python() [0x525d17]\nframe #6: _PyObject_MakeTpCall + 0x254 (0x502a14 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #7: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5541c3]\nframe #8: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b51d]\nframe #9: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #10: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b0d0]\nframe #11: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #12: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b0d0]\nframe #13: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #14: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b75e]\nframe #15: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5a6cea]\nframe #16: _PyEval_EvalFrameDefault + 0x53b (0x50eb6b in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #17: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5c83fe]\nframe #18: PyEval_EvalCode + 0x9f (0x5c7aff in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #19: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5e1683]\nframe #20: _PyEval_EvalFrameDefault + 0x3a22 (0x512052 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #21: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #22: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #23: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #24: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #25: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #26: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5df096]\nframe #27: _PyEval_EvalFrameDefault + 0x35e4 (0x511c14 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #28: /home/msaad/miniconda3/envs/thesis/bin/python() [0x55451f]\nframe #29: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5541c3]\nframe #30: PyObject_Call + 0x9d (0x53ef0d in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x42da (0x51290a in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #32: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #33: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #34: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #35: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #36: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #37: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #38: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #39: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #40: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #41: <unknown function> + 0x79e7 (0x7f6d5c0bb9e7 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\nframe #42: /home/msaad/miniconda3/envs/thesis/bin/python() [0x52405b]\nframe #43: /home/msaad/miniconda3/envs/thesis/bin/python() [0x4bf4de]\nframe #44: /home/msaad/miniconda3/envs/thesis/bin/python() [0x4c13c9]\nframe #45: /home/msaad/miniconda3/envs/thesis/bin/python() [0x51bef7]\nframe #46: _PyEval_EvalFrameDefault + 0x9353 (0x517983 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #47: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5c83fe]\nframe #48: PyEval_EvalCode + 0x9f (0x5c7aff in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #49: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5e1683]\nframe #50: /home/msaad/miniconda3/envs/thesis/bin/python() [0x51bef7]\nframe #51: PyObject_Vectorcall + 0x31 (0x51bde1 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x753 (0x50ed83 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #53: _PyFunction_Vectorcall + 0x173 (0x534f13 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #54: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5f33ef]\nframe #55: Py_RunMain + 0x14a (0x5f2dfa in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #56: Py_BytesMain + 0x39 (0x5b6f49 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #57: <unknown function> + 0x29d90 (0x7f6d5d33fd90 in /lib/x86_64-linux-gnu/libc.so.6)\nframe #58: __libc_start_main + 0x80 (0x7f6d5d33fe40 in /lib/x86_64-linux-gnu/libc.so.6)\nframe #59: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5b6d9f]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Now call the train function\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     17\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m src, tgt \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(src, tgt)\n\u001b[1;32m     20\u001b[0m         src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mSeq2SeqDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     19\u001b[0m     context, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 20\u001b[0m     context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     21\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(target)])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context, target\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     19\u001b[0m     context, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 20\u001b[0m     context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(context)])\n\u001b[1;32m     21\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(target)])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context, target\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Token what not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f6cc5d7dd87 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f6cc5d2e75f in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f6bb22418b4 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1dc5b (0x7f6c082a9c5b in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3dee7 (0x7f6c082c9ee7 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/site-packages/torchtext/_torchtext.so)\nframe #5: /home/msaad/miniconda3/envs/thesis/bin/python() [0x525d17]\nframe #6: _PyObject_MakeTpCall + 0x254 (0x502a14 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #7: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5541c3]\nframe #8: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b51d]\nframe #9: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #10: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b0d0]\nframe #11: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #12: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b0d0]\nframe #13: _PyEval_EvalFrameDefault + 0xfbd (0x50f5ed in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #14: /home/msaad/miniconda3/envs/thesis/bin/python() [0x57b75e]\nframe #15: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5a6cea]\nframe #16: _PyEval_EvalFrameDefault + 0x53b (0x50eb6b in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #17: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5c83fe]\nframe #18: PyEval_EvalCode + 0x9f (0x5c7aff in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #19: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5e1683]\nframe #20: _PyEval_EvalFrameDefault + 0x3a22 (0x512052 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #21: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #22: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #23: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #24: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #25: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #26: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5df096]\nframe #27: _PyEval_EvalFrameDefault + 0x35e4 (0x511c14 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #28: /home/msaad/miniconda3/envs/thesis/bin/python() [0x55451f]\nframe #29: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5541c3]\nframe #30: PyObject_Call + 0x9d (0x53ef0d in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x42da (0x51290a in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #32: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #33: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #34: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #35: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #36: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #37: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #38: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #39: _PyEval_EvalFrameDefault + 0x32d9 (0x511909 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #40: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5dc8ca]\nframe #41: <unknown function> + 0x79e7 (0x7f6d5c0bb9e7 in /home/msaad/miniconda3/envs/thesis/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\nframe #42: /home/msaad/miniconda3/envs/thesis/bin/python() [0x52405b]\nframe #43: /home/msaad/miniconda3/envs/thesis/bin/python() [0x4bf4de]\nframe #44: /home/msaad/miniconda3/envs/thesis/bin/python() [0x4c13c9]\nframe #45: /home/msaad/miniconda3/envs/thesis/bin/python() [0x51bef7]\nframe #46: _PyEval_EvalFrameDefault + 0x9353 (0x517983 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #47: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5c83fe]\nframe #48: PyEval_EvalCode + 0x9f (0x5c7aff in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #49: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5e1683]\nframe #50: /home/msaad/miniconda3/envs/thesis/bin/python() [0x51bef7]\nframe #51: PyObject_Vectorcall + 0x31 (0x51bde1 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x753 (0x50ed83 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #53: _PyFunction_Vectorcall + 0x173 (0x534f13 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #54: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5f33ef]\nframe #55: Py_RunMain + 0x14a (0x5f2dfa in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #56: Py_BytesMain + 0x39 (0x5b6f49 in /home/msaad/miniconda3/envs/thesis/bin/python)\nframe #57: <unknown function> + 0x29d90 (0x7f6d5d33fd90 in /lib/x86_64-linux-gnu/libc.so.6)\nframe #58: __libc_start_main + 0x80 (0x7f6d5d33fe40 in /lib/x86_64-linux-gnu/libc.so.6)\nframe #59: /home/msaad/miniconda3/envs/thesis/bin/python() [0x5b6d9f]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Setup the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Define a loss function, ignoring the padding index in the loss calculation\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def train(model, data_loader, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for src, tgt in data_loader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:-1, :]\n",
    "            targets = tgt[1:, :]  # targets do not include the <sos> token\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_masks(src, tgt_input, pad_idx=vocab['<pad>'])\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "\n",
    "            loss = criterion(output, targets.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "def create_masks(src, tgt, pad_idx):\n",
    "    src_seq_len = src.size(0)\n",
    "    tgt_seq_len = tgt.size(0)\n",
    "\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len).to(device)\n",
    "    \n",
    "    src_padding_mask = (src == pad_idx).transpose(0, 1).to(device)\n",
    "    tgt_padding_mask = (tgt == pad_idx).transpose(0, 1).to(device)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "# Now call the train function\n",
    "train(model, train_loader, optimizer, criterion, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"msaad02/brockport-gpt-4-qa\")['train'].to_pandas()\n",
    "\n",
    "# Create a list of tuples (context, target)\n",
    "data = list(zip(dataset['question'].tolist(), dataset['answer'].tolist()))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Randomly split data into train and validation\n",
    "split_idx = int(0.85 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "# Define tokenizer and vocabulary\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "\n",
    "def build_vocab(data, tokenizer):\n",
    "    token_generator = (token for _, sent in data for token in tokenizer(sent))\n",
    "    return build_vocab_from_iterator([token_generator], specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"], special_first=True, min_freq=5)\n",
    "\n",
    "\n",
    "vocab = build_vocab(train_data + val_data, tokenizer)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, data, vocab, tokenizer):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        context = torch.tensor([self.vocab[token] for token in self.tokenizer(context)])\n",
    "        target = torch.tensor([self.vocab[token] for token in self.tokenizer(target)])\n",
    "        return context, target\n",
    "    \n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Seq2SeqDataset(train_data, vocab, tokenizer)\n",
    "val_dataset = Seq2SeqDataset(val_data, vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who should i contact if i have questions about the status of my transcript order at suny brockport ?\n",
      "if you have any inquiries regarding your transcript order ' s status , you can reach out to credentials inc . at ( <unk> ) <unk> . they ' ll be able to assist you with any questions or concerns you might have about your order .\n"
     ]
    }
   ],
   "source": [
    "train_dataset[0][0].cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "print(\" \".join(vocab.lookup_tokens(train_dataset[0][0].cpu().numpy().tolist())))\n",
    "print(\" \".join(vocab.lookup_tokens(train_dataset[0][1].cpu().numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 9,\n",
       " 34,\n",
       " 53,\n",
       " 545,\n",
       " 559,\n",
       " 12,\n",
       " 988,\n",
       " 842,\n",
       " 10,\n",
       " 22,\n",
       " 504,\n",
       " 4,\n",
       " 9,\n",
       " 20,\n",
       " 74,\n",
       " 48,\n",
       " 6,\n",
       " 1818,\n",
       " 3066,\n",
       " 5,\n",
       " 23,\n",
       " 50,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 5,\n",
       " 51,\n",
       " 10,\n",
       " 39,\n",
       " 33,\n",
       " 748,\n",
       " 6,\n",
       " 127,\n",
       " 9,\n",
       " 19,\n",
       " 53,\n",
       " 119,\n",
       " 24,\n",
       " 388,\n",
       " 9,\n",
       " 352,\n",
       " 34,\n",
       " 54,\n",
       " 12,\n",
       " 842,\n",
       " 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10288"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1816"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 325,   30,    7,  541,  158,   13,  313,   32,  217,   15,    7,  610,\n",
       "            8, 2278,  122,   40, 1766]),\n",
       " tensor([  27,   10,   29,  174,    9,   10,   29,  475, 1575,    6,   25,   21,\n",
       "           16,   13,  313,   32,  264,    6,  260,    7,  610,    8, 2278,  122,\n",
       "           40,    4,    7,  402,  355,   13,    7,  288,  115,   18,  702,  343,\n",
       "            5,   63,  111,    6,   95,   12,   77,   15,   36,  382,    6,  194,\n",
       "           12,  196,   19,  144,   16]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142, 20, 767, 99, 1766]\n",
      "['how', 'can', 'i', 'apply', '?']\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I apply?\"\n",
    "inputs = tokenizer(question)\n",
    "\n",
    "ids = vocab.forward(inputs)\n",
    "print(ids)\n",
    "\n",
    "txt = vocab.lookup_tokens(ids)\n",
    "print(txt)\n",
    "\n",
    "# vocab.get_itos()[5896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = vocab.lookup_tokens([0])\n",
    "txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
