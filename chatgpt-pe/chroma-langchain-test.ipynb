{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from chromadb.utils import embedding_functions\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./db_split', glob=\"./*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of 'db_split/chunk_10481.txt' is 'message/news'. This file type is not currently supported in unstructured.\n",
      "The MIME type of 'db_split/chunk_4148.txt' is 'message/news'. This file type is not currently supported in unstructured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print number of txt files in directory\n",
    "\n",
    "doc = loader.load()\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter (chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(doc)\n",
    "\n",
    "\n",
    "# Count the number of chunks\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InstructorEmbeddingFunction' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m persist_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m embedding_function \u001b[39m=\u001b[39m embedding_functions\u001b[39m.\u001b[39mInstructorEmbeddingFunction(\n\u001b[1;32m      4\u001b[0m     model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhkunlp/instructor-large\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m vectordb \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m     10\u001b[0m     documents\u001b[39m=\u001b[39;49mdoc,\n\u001b[1;32m     11\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding_function,\n\u001b[1;32m     12\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qlora/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:564\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    563\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 564\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    565\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    566\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    567\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    568\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    569\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    570\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    571\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    572\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    573\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    574\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    575\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qlora/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:519\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    487\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    488\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    499\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    500\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    520\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    521\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    522\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    523\u001b[0m         client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    524\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    525\u001b[0m         collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    526\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    527\u001b[0m     )\n\u001b[1;32m    528\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n\u001b[1;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/miniconda3/envs/qlora/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:112\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persist_directory \u001b[39m=\u001b[39m (\n\u001b[1;32m    106\u001b[0m         _client_settings\u001b[39m.\u001b[39mpersist_directory \u001b[39mor\u001b[39;00m persist_directory\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mget_or_create_collection(\n\u001b[1;32m    111\u001b[0m     name\u001b[39m=\u001b[39mcollection_name,\n\u001b[0;32m--> 112\u001b[0m     embedding_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    115\u001b[0m     metadata\u001b[39m=\u001b[39mcollection_metadata,\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverride_relevance_score_fn \u001b[39m=\u001b[39m relevance_score_fn\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InstructorEmbeddingFunction' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "\n",
    "embedding_function = embedding_functions.InstructorEmbeddingFunction(\n",
    "    model_name=\"hkunlp/instructor-large\", \n",
    "    device=\"cuda\"\n",
    ")\n",
    "instructor_collection = client.create_collection(name=\"instructor_embeddings\", embedding_function=embedding_function)\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "instructor_collection = client.create_collection(name=\"instructor_embeddings\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document', 'This is another document']],\n",
       " 'metadatas': [[{'source': 'my_source'}, {'source': 'my_source'}]],\n",
       " 'distances': [[0.10136578232049942, 0.1460421085357666]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor_collection.add(\n",
    "    documents=[\"This is a document\", \"This is another document\"],\n",
    "    metadatas=[{\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")\n",
    "\n",
    "results = instructor_collection.query(\n",
    "    query_texts=[\"This is a query document\"],\n",
    "    n_results=3\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Collection.add() takes from 2 to 6 positional arguments but 20186 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m instructor_collection\u001b[39m.\u001b[39;49madd(\u001b[39m*\u001b[39;49mtexts)\n",
      "\u001b[0;31mTypeError\u001b[0m: Collection.add() takes from 2 to 6 positional arguments but 20186 were given"
     ]
    }
   ],
   "source": [
    "instructor_collection.add(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Before depending exclusively on personal protective equipment such as eye protection, it is preferable that the above hazards are eliminated or minimized by (1) substitution, (2) engineering controls, or (3) administrative controls whenever possible.', metadata={'source': 'db_split/chunk_12688.txt'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
