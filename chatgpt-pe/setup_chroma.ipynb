{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "import chromadb\n",
    "\n",
    "ef = embedding_functions.InstructorEmbeddingFunction(\n",
    "    model_name=\"hkunlp/instructor-large\", \n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chroma collection\n",
    "collection = client.create_collection(name=\"instructor_embeddings\", embedding_function=ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\"../data-collection/data/sentences.csv\"],\n",
    "    ids=[\"csv1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide either query embeddings or query texts, but not both",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collection\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m      2\u001b[0m     n_results\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qlora/lib/python3.11/site-packages/chromadb/api/models/Collection.py:202\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m# If neither query_embeddings nor query_texts are provided, or both are provided, raise an error\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m (query_embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m query_texts \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    200\u001b[0m     query_embeddings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m query_texts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    201\u001b[0m ):\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must provide either query embeddings or query texts, but not both\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39m# If query_embeddings are not provided, we need to compute them from the query_texts\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m query_embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You must provide either query embeddings or query texts, but not both"
     ]
    }
   ],
   "source": [
    "collection.query(\n",
    "    n_results=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['csv1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['../data-collection/data/sentences.csv']],\n",
       " 'metadatas': [[None]],\n",
       " 'distances': [[0.25982213020324707]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=\"This is a query document\",\n",
    "    n_results=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = pd.read_csv(\"../data-collection/data/sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whether you are a recent graduate or a professional with years of experience, we have resources to meet your career needs. We offer online career resources, career events, networking opportunities, and appointments for our alumni.    We are not affiliated with any career counselo...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_index in range(len(sentences)):\n",
    "    # open the file with write mode\n",
    "    with open(f\"./db_split/chunk_{row_index}.txt\", 'w') as file:\n",
    "        # write a string to the file\n",
    "        file.write(sentences.iloc[row_index, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
